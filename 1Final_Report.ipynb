{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DTSA 5800 Network Analysis for Marketing Analytics - Final Project**\n",
        "\n",
        "Table of Contents:\n",
        "  - About the Project\n",
        "  - About the Data\n",
        "  - Set Up\n",
        "  - Twitter Mentions Network\n",
        "    - Viewing the Data\n",
        "    - Identifying Unique Users\n",
        "    - Filtering Out Users\n",
        "    - Setting Up Helper Functions\n",
        "    - Creating the Graph\n",
        "    - Creating Subgraphs\n",
        "    - Saving and Plotting the Graphs\n",
        "  - Semantic Network\n",
        "    - Setting Up Helper Functions\n",
        "    - Identifying Unique Words\n",
        "    - Creating the Graph\n",
        "    - Creating the Subgraphs\n",
        "    - Saving and Plotting the Graphs\n",
        "  - Conclusion/Analysis\n",
        "    - Twitter Mentions Network\n",
        "    - Semantic Network\n",
        "  - References"
      ],
      "metadata": {
        "id": "tMTvtHmmCp2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **About the Project**"
      ],
      "metadata": {
        "id": "K7YFfngGtWp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project was completed as the final project for CU Boulder's DTSA 5800 Network Analysis for Marketing Analytics course in the MS-DS program. The overarching goal of the project is to leverage network graphs to gain insight into how consumers interact with and talk about three competing brands: Nike, Adidas, and Lululemon. More specifically, by constructing network graphs based upon Twitter tweets, this project will first analyze the connections created from Twitter mentions. These mentions, e.g., @nike, @adidas, @lululemon, are typically from consumers of the brands interacting with either the brands themselves or adjacent entities. These mentions graphs will assist in identifying the users that are most centrally related to the brand. Next, this project will also create semantic network graphs, which will reveal what words in the tweets are most commonly associated with eachother. This may provide further insight into what consumers are saying about each brand.   "
      ],
      "metadata": {
        "id": "9II8j1nttaup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project was completed in Google Colab. Moreover, this project is an adapted work, which attempts to follow along with and improve the original/similar work done by the professor of the course. Overall, this project provided a great opportunity to learn about the development of network graphs, namely by using [NetworkX](https://networkx.org/)."
      ],
      "metadata": {
        "id": "b4e2QygDvaZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All project files, including this Colab notebook, the dataset used (in .jsonl and .jsonl.gz formats), and all created graphs can be found in this link to [Google Drive](https://drive.google.com/drive/folders/1rrRiAegl6A-P6BVP3oRLgpZQmyP8J-jR?usp=sharing)."
      ],
      "metadata": {
        "id": "Do5sGRjjYLR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **About the Data**"
      ],
      "metadata": {
        "id": "34Zh5RTItY7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data used in this project consists of 175,077 tweets that mention one or more of the following brands: @nike, @adidas, @lululemon. The data was originally retrieved from Twitter's [Standard search API](https://developer.x.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets). All tweets were sent from the US and are in English. The data comes in .jsonl format (JSON lines)."
      ],
      "metadata": {
        "id": "ZYNm3tepx1V6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3kB9C46RS9r"
      },
      "source": [
        "---\n",
        "## **Set Up**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqGh0Gl9XfHx",
        "outputId": "43bbaff2-b1cc-4ec6-9e6a-9553640b6f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mounting to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBeQ4uklRb3q",
        "outputId": "e79dcccb-b41a-4792-82c6-a8625fc0286d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-] Importing packages...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Loading necessary packages\n",
        "print('[-] Importing packages...')\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "from time import sleep\n",
        "import re\n",
        "import string\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjk-rdL4X2gy",
        "outputId": "e81a4fef-b61a-4b47-f4ea-15711705cbfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-] Importing packages...\n"
          ]
        }
      ],
      "source": [
        "# Loading necessary packages\n",
        "print('[-] Importing packages...')\n",
        "try:\n",
        "  import pyvis\n",
        "  from pyvis.network import Network\n",
        "except:\n",
        "  !pip install pyvis\n",
        "  import pyvis\n",
        "  from pyvis.network import Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qmxQEV-YHzb"
      },
      "outputs": [],
      "source": [
        "# Setting working directory\n",
        "WORKING_DIR = \"/content/drive/MyDrive/MSDS_marketing_text_analytics/master_files/3_network_analysis\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OLS2o-NYeRc"
      },
      "outputs": [],
      "source": [
        "# Setting filepath for tweets dataset\n",
        "FILE_PATH = '%s/nikelululemonadidas_tweets.jsonl' % WORKING_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pes0KIqZRcTA"
      },
      "source": [
        "---\n",
        "## **Twitter Mentions Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QKtp4itbmm8"
      },
      "source": [
        "### **Viewing the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69naVcRWRuXK"
      },
      "outputs": [],
      "source": [
        "# Opening 'nikelululemonadidas_tweets.jsonl' file and saving as variable 'json_file'\n",
        "# jsonl = json line, each line of the text file corresponds to a json entry\n",
        "json_file = open(FILE_PATH, 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5YmF7dLZk2f",
        "outputId": "d5e364ab-82d0-4cfc-ca85-16297746be4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Via Nike‚Å† SNKRS: can I get a W ‚Å¶@Nike‚Å© ‚Å¶@nikebasketball‚Å© #snkrs  https://t.co/lQ6zKN1Oq6\n",
            "@Kaya_Alexander5 @nikestore @Nike @SneakerAdmirals Jelly!   Awesome pair https://t.co/L2Kefg2fUP\n",
            "RT @WALionsFB: Game Recap from #MondayNightFootball‚ÄºÔ∏èüèà @jumpman23 @usnikefootball @wacad @larryblustein @RiddellSports @Nike @FlaHSFootball‚Ä¶\n",
            "@somaliboxer @AlisSistersClub @nikelondon @Nike Fists up ‚ù§Ô∏è\n",
            "RT @NiaOnAir: Identity is not as simple as black and white. ‚òØ On episode 5 of @nike's #ComeThru, I get into it with @lisa_asano, @whoisumi,‚Ä¶\n",
            "RT @WALionsFB: Game Recap from #MondayNightFootball‚ÄºÔ∏èüèà @jumpman23 @usnikefootball @wacad @larryblustein @RiddellSports @Nike @FlaHSFootball‚Ä¶\n",
            "Liquid3_6 Sneaker Of The Day @nike \n",
            "\n",
            "Saquon Barkley x Nike Air Trainer 3\n",
            "Color: Pearl White/Neptune Green-Sail\n",
            "Style Code: DA5403-200\n",
            "Release Date: October 8, 2021\n",
            "Price: $140\n",
            "#sneakerhead #style #fashion #sneakeroftheday #sneakers #footwear #brandmarketing #Nike #Liquid3_6üõ∏ https://t.co/kwIROtsn1k\n"
          ]
        }
      ],
      "source": [
        "# Iterating through 'json_file' to see what the data looks like\n",
        "\n",
        "# Iterating through file, if less than 50 and involves 'nike', print out the tweet\n",
        "for i, atweet in enumerate(json_file):\n",
        "    if i < 50:\n",
        "      tweetjson = json.loads(atweet)\n",
        "      text = tweetjson['full_text']\n",
        "      if \"nike\" in text:\n",
        "        print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1h52LgRcCtD"
      },
      "source": [
        "### **Identifying Unique Users**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8c3MahQbrN7"
      },
      "outputs": [],
      "source": [
        "# Reopening 'nikelululemonadidas_tweets.jsonl' file in order to iterate through it again\n",
        "json_file = open(FILE_PATH, 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-ciKeTIfj6S",
        "outputId": "18df9d64-02b9-4359-ae3d-232ce68710a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tweets iterated\n",
            "10000 tweets iterated\n",
            "20000 tweets iterated\n",
            "30000 tweets iterated\n",
            "40000 tweets iterated\n",
            "50000 tweets iterated\n",
            "60000 tweets iterated\n",
            "70000 tweets iterated\n",
            "80000 tweets iterated\n",
            "90000 tweets iterated\n",
            "100000 tweets iterated\n",
            "110000 tweets iterated\n",
            "120000 tweets iterated\n",
            "130000 tweets iterated\n",
            "140000 tweets iterated\n",
            "150000 tweets iterated\n",
            "160000 tweets iterated\n",
            "170000 tweets iterated\n"
          ]
        }
      ],
      "source": [
        "# Identifying unique users in the mention network\n",
        "\n",
        "# Creating a dictionary of all unique users\n",
        "unique_users = {}\n",
        "\n",
        "# Iterating through 'json_file'\n",
        "for i, atweet in enumerate(json_file):\n",
        "    # Creating counter to show iteration progress\n",
        "    if i % 10000 == 0:\n",
        "      print(\"%s tweets iterated\" % i)\n",
        "    # Loading in file as string with 'json.loads'\n",
        "    tweet_json = json.loads(atweet)\n",
        "    # Parsing out user, id, and follower count from tweets\n",
        "    user_who_tweeted = tweet_json['user']['screen_name']\n",
        "    id_who_tweeted = tweet_json['user']['id']\n",
        "    follower_count = tweet_json['user']['followers_count']\n",
        "    # Counting number of tweets by a given user\n",
        "    if id_who_tweeted in unique_users:\n",
        "      unique_users[id_who_tweeted]['tweet_count'] += 1\n",
        "      #if unique_users[id_who_tweeted]['followers_count'] == 0:\n",
        "      unique_users[id_who_tweeted]['followers_count'] = follower_count\n",
        "      #unique_users[id_who_tweeted]['screen_name'] = user_who_tweeted.lower()\n",
        "    # Adding new ids to dictionary, including tweet count and follower count\n",
        "    if id_who_tweeted not in unique_users:\n",
        "      unique_users[id_who_tweeted] = {}\n",
        "      unique_users[id_who_tweeted]['tweet_count'] = 1\n",
        "      unique_users[id_who_tweeted]['mention_count'] = 0\n",
        "      unique_users[id_who_tweeted]['id'] = id_who_tweeted\n",
        "      unique_users[id_who_tweeted]['followers_count'] = follower_count\n",
        "      unique_users[id_who_tweeted]['screen_name'] = user_who_tweeted.lower()\n",
        "    # Adding in mentioned users\n",
        "    users_mentioned = tweet_json['entities']['user_mentions']\n",
        "    # If the tweet mentions other users in the tweet\n",
        "    if len(users_mentioned) > 0:\n",
        "      # Iterating through each mention in the tweet\n",
        "      for user_mentioned in users_mentioned:\n",
        "        # Extracting details about user\n",
        "        screen_name_mentioned = user_mentioned['screen_name']\n",
        "        id_mentioned = user_mentioned['id']\n",
        "        # Increasing mention count\n",
        "        if id_mentioned in unique_users:\n",
        "          unique_users[id_mentioned]['mention_count'] += 1\n",
        "        # Extracting details about mentioned user\n",
        "        if id_mentioned not in unique_users:\n",
        "          unique_users[id_mentioned] = {}\n",
        "          unique_users[id_mentioned]['tweet_count'] = 0\n",
        "          unique_users[id_mentioned]['mention_count'] = 1\n",
        "          unique_users[id_mentioned]['id'] = id_mentioned\n",
        "          unique_users[id_mentioned]['followers_count'] = 0\n",
        "          unique_users[id_mentioned]['screen_name'] = screen_name_mentioned.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYGHWEFafyHy",
        "outputId": "72ed1915-adec-48bf-96b6-c913383d5b47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175077"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Checking the total number of tweets\n",
        "i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMYCg15Wf3ch",
        "outputId": "91da3099-cf57-4bf8-97c4-f155045219a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131663"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Checking the number of unique users\n",
        "len(unique_users)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhFksy42cVJO"
      },
      "source": [
        "### **Filtering Out Users**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr1XYtjVcYG4",
        "outputId": "1a1163e2-baf5-4d82-f59c-15839e482d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 415859364 \tscreen_name: nike\n",
            "id: 300114634 \tscreen_name: adidas\n",
            "id: 16252784 \tscreen_name: lululemon\n",
            "198\n"
          ]
        }
      ],
      "source": [
        "# We can't really have 131,663 unique nodes, we need to filter down!\n",
        "\n",
        "# Creating a set of users to include\n",
        "users_to_include = set()\n",
        "\n",
        "# Creating a list of brand users\n",
        "brand_users = ['nike', 'lululemon', 'adidas']\n",
        "\n",
        "# Filtering down users to 2+ tweets and > 100,000 followers\n",
        "user_count = 0\n",
        "for auser in unique_users:\n",
        "  if unique_users[auser]['screen_name'] in brand_users:\n",
        "      print('id:', auser, '\\tscreen_name:', unique_users[auser]['screen_name'])\n",
        "      user_count += 1\n",
        "      users_to_include.add(auser)\n",
        "  elif unique_users[auser]['tweet_count'] >= 2:\n",
        "    if unique_users[auser]['followers_count'] >= 100000:\n",
        "      user_count += 1\n",
        "      users_to_include.add(auser)\n",
        "\n",
        "print(len(users_to_include))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQJ_D172lp50",
        "outputId": "3b638788-d18b-489e-87bd-437659745a73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001503839347424865"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Comparing length of original number of unique users and filtered users, 99% reduction!\n",
        "len(users_to_include) / len(unique_users)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the counts for the major brands\n",
        "print(\"Nike:\", unique_users[415859364])\n",
        "print(\"Adidas:\", unique_users[300114634])\n",
        "print(\"Lululemon:\", unique_users[16252784])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvHWokhD5ih5",
        "outputId": "83d75557-a70f-4899-ae8a-8b17769b5b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nike: {'tweet_count': 0, 'mention_count': 120125, 'id': 415859364, 'followers_count': 0, 'screen_name': 'nike'}\n",
            "Adidas: {'tweet_count': 3, 'mention_count': 36654, 'id': 300114634, 'followers_count': 4082910, 'screen_name': 'adidas'}\n",
            "Lululemon: {'tweet_count': 0, 'mention_count': 6294, 'id': 16252784, 'followers_count': 0, 'screen_name': 'lululemon'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting Up Helper Functions for Graph Analysis and Plotting**"
      ],
      "metadata": {
        "id": "ZxCOrC4UbjlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating helper function for graph analysis\n",
        "def graph_summary_stats(G, title='Graph Summary'):\n",
        "  # Display a summary of the graph object created\n",
        "  # https://networkx.org/documentation/stable/reference/functions.html\n",
        "  print('----------------------------------------')\n",
        "  print('#####', title, '#####')\n",
        "  print('number of nodes:', nx.number_of_nodes(G))\n",
        "  print('number of edges:', nx.number_of_edges(G))\n",
        "  print()\n",
        "  print('nodes:', nx.nodes(G))\n",
        "  print()\n",
        "  if G.has_node('adidas'):\n",
        "    print('neighbors of adidas:', list(nx.all_neighbors(G, 'adidas')))\n",
        "  if G.has_node('nike'):\n",
        "    print('neighbors of nike:', list(nx.all_neighbors(G, 'nike')))\n",
        "  if G.has_node('lululemon'):\n",
        "   print('neighbors of lululemon:', list(nx.all_neighbors(G, 'lululemon')))\n",
        "  print('----------------------------------------\\n')"
      ],
      "metadata": {
        "id": "T88bjLS8bo1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating helper function to plot graphs and save to png\n",
        "def plot_graph(G, file_path='temp_file', use_edge_weight=True, plot_size='large'):\n",
        "\n",
        "  # Defining node colors\n",
        "  default_color = 'blue'\n",
        "  highlight_color = 'red'\n",
        "  brand_users = ['nike', 'lululemon', 'adidas']\n",
        "  node_colors = [highlight_color if node in brand_users else default_color for node in G.nodes()]\n",
        "\n",
        "  # Setting plot sizes\n",
        "  if plot_size == 'medium-large':\n",
        "    p_figsize = (150, 150)\n",
        "    p_font_size = 20\n",
        "    p_edge_width_scale = 2\n",
        "    p_node_size = 5000\n",
        "    p_arrow_size = 50\n",
        "    p_k = None\n",
        "  if plot_size == 'medium':\n",
        "    p_figsize = (25, 25)\n",
        "    p_font_size = 12\n",
        "    p_edge_width_scale = 2\n",
        "    p_node_size = 3000\n",
        "    p_arrow_size = 50\n",
        "    p_k = None\n",
        "  elif plot_size == 'small':\n",
        "    p_figsize = (50, 50)\n",
        "    p_font_size = 20\n",
        "    p_edge_width_scale = 2\n",
        "    p_node_size = 30000\n",
        "    p_arrow_size = 100\n",
        "    p_k = None\n",
        "  elif plot_size == 'x-small':\n",
        "    p_figsize = (12, 12)\n",
        "    p_font_size = 20\n",
        "    p_edge_width_scale = 2\n",
        "    p_node_size = 5000\n",
        "    p_arrow_size = 100\n",
        "    p_k = None\n",
        "  else:\n",
        "    p_figsize = (300, 300)\n",
        "    p_font_size = 20\n",
        "    p_edge_width_scale = 2\n",
        "    p_node_size = 3000\n",
        "    p_arrow_size = 100\n",
        "    p_k = None\n",
        "\n",
        "  # Generating spring layout for graphs\n",
        "  positions = nx.spring_layout(G, k=p_k)\n",
        "\n",
        "  # Extracting edge weights for drawing\n",
        "  if use_edge_weight == True:\n",
        "    p_edge_weights = p_edge_width_scale*[G[u][v]['weight'] for u, v in G.edges()]\n",
        "  else:\n",
        "    p_edge_weights = p_edge_width_scale\n",
        "\n",
        "  # Creating graph\n",
        "  fig, ax = plt.subplots(1, 1, figsize=p_figsize)\n",
        "  nx.draw_networkx(G, pos=positions, ax=ax, node_color=node_colors,\n",
        "                   font_color=\"#FFFFFF\", font_size=p_font_size,\n",
        "                   node_size=p_node_size, width=p_edge_weights,\n",
        "                   arrows=True, arrowsize=p_arrow_size)\n",
        "  # Saving the graph as a png to the working directory\n",
        "  print_file_path = '%s/%s.png' % (WORKING_DIR, file_path)\n",
        "  plt.savefig(print_file_path, format='PNG')\n",
        "  plt.close('all')\n"
      ],
      "metadata": {
        "id": "8yG8C8RCb51O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deQKFa2xcb9t"
      },
      "source": [
        "### **Creating the Graph**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMJlXvYKcg4k"
      },
      "outputs": [],
      "source": [
        "# Reopening json file again to reiterate\n",
        "json_file = open(FILE_PATH, 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwqDEv4Zm3z0"
      },
      "outputs": [],
      "source": [
        "# Preparing directional graph\n",
        "Mentions_Graph = nx.DiGraph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKik-393m5vv",
        "outputId": "9a169d05-54d8-489f-b180-49d612fe81cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tweets iterated\n",
            "10000 tweets iterated\n",
            "20000 tweets iterated\n",
            "30000 tweets iterated\n",
            "40000 tweets iterated\n",
            "50000 tweets iterated\n",
            "60000 tweets iterated\n",
            "70000 tweets iterated\n",
            "80000 tweets iterated\n",
            "90000 tweets iterated\n",
            "100000 tweets iterated\n",
            "110000 tweets iterated\n",
            "120000 tweets iterated\n",
            "130000 tweets iterated\n",
            "140000 tweets iterated\n",
            "150000 tweets iterated\n",
            "160000 tweets iterated\n",
            "170000 tweets iterated\n"
          ]
        }
      ],
      "source": [
        "# Identifying unique users in the mention network\n",
        "\n",
        "# Similar steps as before, iterating through the file, extracting screen name, id, and follower count\n",
        "for i, atweet in enumerate(json_file):\n",
        "    # Creating counter to track progress\n",
        "    if i % 10000 == 0:\n",
        "      print(\"%s tweets iterated\" % i)\n",
        "    tweet_json = json.loads(atweet)\n",
        "    # Extracting screen name, id, follower count\n",
        "    user_who_tweeted = tweet_json['user']['screen_name'].lower()\n",
        "    id_who_tweeted = tweet_json['user']['id']\n",
        "    follower_count = tweet_json['user']['followers_count']\n",
        "    # If id is in filtered user list, we pull out the users they mention in a tweet\n",
        "    if id_who_tweeted in users_to_include:\n",
        "      users = tweet_json['entities']['user_mentions']\n",
        "      if len(users) > 0:\n",
        "          # Iterating through users being mentioned, extracting their screen name and id\n",
        "          for auser in users:\n",
        "              screen_name = auser['screen_name'].lower()\n",
        "              mention_id = auser['id']\n",
        "              # Appending this as an edge in the graph\n",
        "              if mention_id in users_to_include:\n",
        "                if user_who_tweeted != screen_name:\n",
        "                  if Mentions_Graph.has_edge(user_who_tweeted, screen_name):\n",
        "                    # If the edge exists, increment its weight\n",
        "                    Mentions_Graph[user_who_tweeted][screen_name]['weight'] += 1\n",
        "                  else:\n",
        "                    # If the edge doesn't exist, add it with weight = 1\n",
        "                    Mentions_Graph.add_edge(user_who_tweeted, screen_name, weight=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the summary of the mentions graph\n",
        "graph_summary_stats(G = Mentions_Graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlbUxBtLow-j",
        "outputId": "2212b0ca-2b41-45c1-cba4-6ce78204ed0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "##### Graph Summary #####\n",
            "number of nodes: 194\n",
            "number of edges: 339\n",
            "\n",
            "nodes: ['kiganyi_', 'adidas', 'undefeatedinc', 'uniwatch', 'nike', 'atari_jones', 'adidasoriginals', 'solefed', 'jumpman23', 'bajabiri', 'golfdigest', 'lululemon', 'jonahlupton', 'nikestore', 'jermainedupri', 'finishline', 'wwd', 'hiphopwired', 'xboxwire', 'aarongreenberg', 'xbox', 'xboxp3', 'predsnhl', 'lakings', 'dashiexp', 'fastcompany', 'reignofapril', 'nrarmour', 'sbjsbd', 'barcaacademy', 'khou', 'oakley', 'marshablackburn', 'senrickscott', 'schuh', 'dezeen', 'lebatardshow', 'billiejeanking', 'barrysanders', 'complex', 'brooksrunning', 'adidasrunning', 'wiedenkennedy', 'bottom2thatop', 'candace_parker', 'snkr_twitr', 'katgraham', 'joshog', 'adweek', 'kingjames', 'jamesgunn', 'pomklementieff', 'loyalty360', 'jasonlacanfora', 'kohls', '7newsdc', 'realrclark25', 'adidashoops', 'wnba', 'barondavis', 'metropolismag', 'legiqn', 'fatkiddeals', 'jack_p', 'nyctsubway', 'nikebasketball', 'slamonline', 'rga', 'stockx', 'gladstein', 'msmelchen', 'sproutsocial', 'orioles', 'natbrunell', 'fousey', 'okayplayer', 'sacramentokings', 'yahoofinance', 'enesfreedom', 'redsteeze', 'sethamandel', 'slimjim', 'tengbiao', 'hughhewitt', 'muslimmatters', 'nedryun', 'ericmmatheny', 'lifeatpurdue', 'epochtimes', 'suns', 'donaldjtrumpjr', 'joshrogin', 'yesnicksearcy', 'highsnobiety', 'lasparks', 'realunogame', 'giannis_an34', 'deezefi', 'mrleonardkim', 'evankirstel', 'mattel', 'reebok', 'pennstatefball', 'stevedeaceshow', 'girlsintech', 'uoregon', 'mystic7', 'ericpmusselman', 'qrich', 'cointelegraph', 'houstondynamo', 'threadreaderapp', 'prestonpysh', 'rwang0', 'tandfn', 'thebussypleaser', 'techinsider', 'jdofficial', 'xlr8r', 'onsoranje', 'liekemartens1', 'knvb', 'realshellyannfp', 'kicksdeals', 'lafc', 'thegrovela', 'lagalaxy', 'adamsconsulting', 'coindesk', 'adidasfootball', 'spicer', 'kieraplease', 'jkylebass', 'kfile', 'sportsiren', 'nicekicks', 'scottwarner18', 'complexstyle', 'tinashe', 'rosgo21', 'roblox', 'bloxy_news', 'insideroblox', 'atmos_usa', 'nwsl', 'adamjacksonsf', 'novambb', 'solomonyue', 'angelaruggiero', 'bauerhockey', 'jenniferwalcott', 'road_2_ft_worth', 'vampybitme', 'iamwellandgood', 'tropofarmer', 'boredelonmusk', 'mattsteffanina', 'mediapost', 'brooklynnets', 'vidcon', 'uninterrupted', 'hunterheather', 'misstabstevens', 'chainlinkgod', '1djfirstclass', 'chsommers', 'tonipayne', 'cowhercbs', 'detroitpistons', 'cory_shoff', 'usa_lacrosse', 'xxxcrypt0', 'ijustine', 'hackapreneur', 'burgerking', 'namecheap', 'campaignbrands', 'elmaaelmoo', 'colethereum', 'nebraskancrypto', 'vaynermedia', 'schmittnyc', 'mpinoe', 'seanmdav', 'hunterw', 'realvision', 'reallisariley', 'rexchapman', 'qiasomar', 'kingofthecrane', 'cnbc', 'ericvdunn', 'trustlessstate', 'lopp']\n",
            "\n",
            "neighbors of adidas: ['kiganyi_', 'undefeatedinc', 'atari_jones', 'bajabiri', 'jermainedupri', 'xboxwire', 'aarongreenberg', 'xboxp3', 'lakings', 'dashiexp', 'xbox', 'wwd', 'hiphopwired', 'billiejeanking', 'complex', 'bottom2thatop', 'katgraham', 'jamesgunn', 'pomklementieff', 'loyalty360', 'kohls', 'uniwatch', 'adidashoops', 'metropolismag', 'adidasrunning', 'legiqn', 'fatkiddeals', 'jack_p', 'nyctsubway', 'snkr_twitr', 'stockx', 'adweek', 'houstondynamo', 'reebok', 'finishline', 'sbjsbd', 'techinsider', 'kicksdeals', 'lafc', 'lagalaxy', 'adidasfootball', 'spicer', 'kfile', 'sportsiren', 'highsnobiety', 'nicekicks', 'adidasoriginals', 'coindesk', 'jenniferwalcott', 'thebussypleaser', 'vampybitme', 'tropofarmer', 'boredelonmusk', 'mattsteffanina', 'brooklynnets', 'hunterheather', 'jdofficial', 'misstabstevens', 'complexstyle', 'chainlinkgod', 'wnba', 'tonipayne', 'predsnhl', 'slamonline', 'schuh', 'xxxcrypt0', 'candace_parker', 'burgerking', 'namecheap', 'iamwellandgood', 'deezefi', 'dezeen', 'hunterw', 'cointelegraph', 'ericvdunn', 'burgerking', 'xbox', 'nike']\n",
            "neighbors of nike: ['uniwatch', 'solefed', 'nikestore', 'undefeatedinc', 'finishline', 'wwd', 'hiphopwired', 'fastcompany', 'reignofapril', 'nrarmour', 'sbjsbd', 'barcaacademy', 'marshablackburn', 'senrickscott', 'schuh', 'dezeen', 'lebatardshow', 'barrysanders', 'brooksrunning', 'wiedenkennedy', 'snkr_twitr', 'jumpman23', 'kingjames', 'jasonlacanfora', '7newsdc', 'barondavis', 'nikebasketball', 'slamonline', 'rga', 'msmelchen', 'sproutsocial', 'orioles', 'natbrunell', 'fousey', 'okayplayer', 'sacramentokings', 'realrclark25', 'enesfreedom', 'redsteeze', 'sethamandel', 'slimjim', 'tengbiao', 'gladstein', 'hughhewitt', 'muslimmatters', 'nedryun', 'ericmmatheny', 'lifeatpurdue', 'epochtimes', 'suns', 'donaldjtrumpjr', 'joshrogin', 'yesnicksearcy', 'highsnobiety', 'lasparks', 'realunogame', 'mrleonardkim', 'evankirstel', 'mattel', 'reebok', 'pennstatefball', 'stevedeaceshow', 'girlsintech', 'uoregon', 'ericpmusselman', 'qrich', 'wnba', 'cointelegraph', 'threadreaderapp', 'prestonpysh', 'rwang0', 'tandfn', 'thebussypleaser', 'techinsider', 'jdofficial', 'xlr8r', 'onsoranje', 'knvb', 'liekemartens1', 'realshellyannfp', 'thegrovela', 'adamsconsulting', 'coindesk', 'giannis_an34', 'kieraplease', 'jkylebass', 'khou', 'scottwarner18', 'kicksdeals', 'nicekicks', 'complexstyle', 'rosgo21', 'roblox', 'bloxy_news', 'insideroblox', 'nwsl', 'adamjacksonsf', 'novambb', 'solomonyue', 'angelaruggiero', 'boredelonmusk', 'vidcon', 'uninterrupted', '1djfirstclass', 'chsommers', 'tonipayne', 'cowhercbs', 'detroitpistons', 'cory_shoff', 'usa_lacrosse', 'hackapreneur', 'tropofarmer', 'burgerking', 'deezefi', 'namecheap', 'mattsteffanina', 'campaignbrands', 'elmaaelmoo', 'mediapost', 'adidas', 'colethereum', 'nebraskancrypto', 'vaynermedia', 'tinashe', 'schmittnyc', 'mpinoe', 'seanmdav', 'realvision', 'xxxcrypt0', 'ijustine', 'bajabiri', 'rexchapman', 'qiasomar', 'kingofthecrane', 'trustlessstate', 'lopp']\n",
            "neighbors of lululemon: ['golfdigest', 'jonahlupton', 'predsnhl', 'khou', 'oakley', 'brooksrunning', 'joshog', 'adweek', 'realrclark25', 'yahoofinance', 'uniwatch', 'deezefi', 'mrleonardkim', 'mystic7', 'evankirstel', 'bauerhockey', 'thegrovela', 'road_2_ft_worth', 'iamwellandgood', 'mediapost', 'ijustine', 'reallisariley', 'wwd', 'cnbc']\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating Subgraphs**"
      ],
      "metadata": {
        "id": "cihG5zAj8-Vr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlSYw99gnIwi"
      },
      "outputs": [],
      "source": [
        "# Creating and defining node interactions and connections\n",
        "# Kudos to 'Chiuchiyin'! The following code chunk has been adapted from their work\n",
        "\n",
        "# Defining key nodes\n",
        "key_nodes_all = ['nike', 'lululemon', 'adidas']\n",
        "key_nodes_nl = ['nike', 'lululemon']\n",
        "key_nodes_na = ['nike', 'adidas']\n",
        "key_nodes_al = ['adidas', 'lululemon']\n",
        "\n",
        "# Finding neighbors of the key nodes by themselves\n",
        "neighbors_sets_n = set(nx.all_neighbors(Mentions_Graph, 'nike'))\n",
        "neighbors_sets_a = set(nx.all_neighbors(Mentions_Graph, 'adidas'))\n",
        "neighbors_sets_l = set(nx.all_neighbors(Mentions_Graph, 'lululemon'))\n",
        "\n",
        "# Finding neighbors of the key nodes\n",
        "neighbors_sets_all = [set(nx.all_neighbors(Mentions_Graph, node)) for node in key_nodes_all]\n",
        "neighbors_sets_nl = [set(nx.all_neighbors(Mentions_Graph, node)) for node in key_nodes_nl]\n",
        "neighbors_sets_na = [set(nx.all_neighbors(Mentions_Graph, node)) for node in key_nodes_na]\n",
        "neighbors_sets_al = [set(nx.all_neighbors(Mentions_Graph, node)) for node in key_nodes_al]\n",
        "\n",
        "# Intersecting the sets to get nodes connected to all key nodes\n",
        "common_neighbors_all = set.intersection(*neighbors_sets_all)\n",
        "\n",
        "# Intersecting the sets to get nodes connected to only 2 key nodes\n",
        "common_neighbors_nl = set.intersection(*neighbors_sets_nl) - common_neighbors_all - set(key_nodes_al)\n",
        "common_neighbors_na = set.intersection(*neighbors_sets_na) - common_neighbors_all - set(key_nodes_nl)\n",
        "common_neighbors_al = set.intersection(*neighbors_sets_al) - common_neighbors_all - set(key_nodes_na)\n",
        "\n",
        "# Getting nodes connected to any one of the key nodes but not all of them\n",
        "union_neighbors = set.union(*neighbors_sets_all)\n",
        "\n",
        "# Getting nodes connected to only 1 brand\n",
        "exclusive_neighbors = (union_neighbors - common_neighbors_all\n",
        "                       - common_neighbors_nl - common_neighbors_na - common_neighbors_al)\n",
        "\n",
        "# Getting nodes connected to each specific brand\n",
        "exclusive_neighbors_n = neighbors_sets_n - common_neighbors_all - common_neighbors_nl - common_neighbors_na - set(key_nodes_al)\n",
        "exclusive_neighbors_a = neighbors_sets_a - common_neighbors_all - common_neighbors_na - common_neighbors_nl - set(key_nodes_nl)\n",
        "exclusive_neighbors_l = neighbors_sets_l - common_neighbors_all - common_neighbors_nl - common_neighbors_al - set(key_nodes_na)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating subgraphs\n",
        "\n",
        "# Creating subgraph of bridges between all brand nodes\n",
        "nodes_to_keep_all = list(common_neighbors_all) + key_nodes_all\n",
        "Mentions_Graph_bridge_all = Mentions_Graph.subgraph(nodes_to_keep_all)\n",
        "\n",
        "# Creating subgraph of bridges between Nike & Adidas\n",
        "nodes_to_keep_na = list(common_neighbors_na) + key_nodes_na\n",
        "Mentions_Graph_bridge_na = Mentions_Graph.subgraph(nodes_to_keep_na)\n",
        "\n",
        "# Creating subgraph of bridges between Nike & Lululemon\n",
        "nodes_to_keep_nl = list(common_neighbors_nl) + key_nodes_nl\n",
        "Mentions_Graph_bridge_nl = Mentions_Graph.subgraph(nodes_to_keep_nl)\n",
        "\n",
        "# Creating subgraph of bridges between Adidas & Lululemon\n",
        "nodes_to_keep_al = list(common_neighbors_al) + key_nodes_al\n",
        "Mentions_Graph_bridge_al = Mentions_Graph.subgraph(nodes_to_keep_al)"
      ],
      "metadata": {
        "id": "H-rdPSaI-SyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the summaries of the new subgraphs\n",
        "graph_summary_stats(G = Mentions_Graph_bridge_all, title='Bridges Between All Brand Nodes')\n",
        "graph_summary_stats(G = Mentions_Graph_bridge_na, title='Nike & Adidas Bridges')\n",
        "graph_summary_stats(G = Mentions_Graph_bridge_nl, title='Nike & Lululemon Bridges')\n",
        "graph_summary_stats(G = Mentions_Graph_bridge_al, title='Adidas & Lululemon Bridges')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xkhVkBM_TqJ",
        "outputId": "f7a90cda-997e-4c6c-e642-7c108d2ba2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "##### Bridges Between All Brand Nodes #####\n",
            "number of nodes: 6\n",
            "number of edges: 10\n",
            "\n",
            "nodes: ['lululemon', 'nike', 'adidas', 'deezefi', 'uniwatch', 'wwd']\n",
            "\n",
            "neighbors of adidas: ['wwd', 'uniwatch', 'deezefi', 'nike']\n",
            "neighbors of nike: ['uniwatch', 'wwd', 'deezefi', 'adidas']\n",
            "neighbors of lululemon: ['uniwatch', 'deezefi', 'wwd']\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "##### Nike & Adidas Bridges #####\n",
            "number of nodes: 29\n",
            "number of edges: 57\n",
            "\n",
            "nodes: ['thebussypleaser', 'burgerking', 'snkr_twitr', 'complexstyle', 'namecheap', 'sbjsbd', 'nike', 'schuh', 'slamonline', 'tonipayne', 'coindesk', 'mattsteffanina', 'highsnobiety', 'reebok', 'wnba', 'dezeen', 'hiphopwired', 'undefeatedinc', 'kicksdeals', 'techinsider', 'tropofarmer', 'nicekicks', 'xxxcrypt0', 'boredelonmusk', 'bajabiri', 'adidas', 'cointelegraph', 'finishline', 'jdofficial']\n",
            "\n",
            "neighbors of adidas: ['undefeatedinc', 'bajabiri', 'hiphopwired', 'snkr_twitr', 'reebok', 'finishline', 'sbjsbd', 'techinsider', 'kicksdeals', 'highsnobiety', 'nicekicks', 'coindesk', 'thebussypleaser', 'tropofarmer', 'boredelonmusk', 'mattsteffanina', 'jdofficial', 'complexstyle', 'wnba', 'tonipayne', 'slamonline', 'schuh', 'xxxcrypt0', 'burgerking', 'namecheap', 'dezeen', 'cointelegraph', 'burgerking', 'nike']\n",
            "neighbors of nike: ['undefeatedinc', 'finishline', 'hiphopwired', 'sbjsbd', 'schuh', 'dezeen', 'snkr_twitr', 'slamonline', 'highsnobiety', 'reebok', 'wnba', 'cointelegraph', 'thebussypleaser', 'techinsider', 'jdofficial', 'coindesk', 'kicksdeals', 'nicekicks', 'complexstyle', 'boredelonmusk', 'tonipayne', 'tropofarmer', 'burgerking', 'namecheap', 'mattsteffanina', 'adidas', 'xxxcrypt0', 'bajabiri']\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "##### Nike & Lululemon Bridges #####\n",
            "number of nodes: 10\n",
            "number of edges: 16\n",
            "\n",
            "nodes: ['lululemon', 'mrleonardkim', 'thegrovela', 'brooksrunning', 'evankirstel', 'nike', 'khou', 'realrclark25', 'mediapost', 'ijustine']\n",
            "\n",
            "neighbors of nike: ['brooksrunning', 'realrclark25', 'mrleonardkim', 'evankirstel', 'thegrovela', 'khou', 'mediapost', 'ijustine']\n",
            "neighbors of lululemon: ['khou', 'brooksrunning', 'realrclark25', 'mrleonardkim', 'evankirstel', 'thegrovela', 'mediapost', 'ijustine']\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "##### Adidas & Lululemon Bridges #####\n",
            "number of nodes: 5\n",
            "number of edges: 6\n",
            "\n",
            "nodes: ['lululemon', 'adidas', 'iamwellandgood', 'adweek', 'predsnhl']\n",
            "\n",
            "neighbors of adidas: ['adweek', 'predsnhl', 'iamwellandgood']\n",
            "neighbors of lululemon: ['predsnhl', 'adweek', 'iamwellandgood']\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Saving and Plotting the Graphs**"
      ],
      "metadata": {
        "id": "tJHmhkxK_8Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and plotting the full graph\n",
        "plot_graph(G = Mentions_Graph, file_path='mentions_network', plot_size='large')"
      ],
      "metadata": {
        "id": "NpnpskVBAKr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and plotting the subgraphs\n",
        "plot_graph(G = Mentions_Graph_bridge_all, file_path='mentions_network_bridge_all', plot_size='small')\n",
        "plot_graph(G = Mentions_Graph_bridge_na, file_path='mentions_network_bridge_nike_adidas', plot_size='small')\n",
        "plot_graph(G = Mentions_Graph_bridge_nl, file_path='mentions_network_bridge_nike_lululemon', plot_size='small')\n",
        "plot_graph(G = Mentions_Graph_bridge_al, file_path='mentions_network_bridge_adidas_lululemon', plot_size='small')"
      ],
      "metadata": {
        "id": "qadojk8vCT4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Semantic Network**"
      ],
      "metadata": {
        "id": "yiFWuDw9dkUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting Up Helper Functions for Data Preprocessing**"
      ],
      "metadata": {
        "id": "k85SC9zHekR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating helper functions for data preprocessing\n",
        "\n",
        "# Creating variable names for nltk functions\n",
        "TWEET_TOKENIZER = nltk.TweetTokenizer().tokenize\n",
        "WORD_TOKENIZER = nltk.tokenize.word_tokenize\n",
        "STEMMER = nltk.PorterStemmer()\n",
        "LEMMATIZER = nltk.WordNetLemmatizer()\n",
        "\n",
        "# Removing URLs\n",
        "def removeURL(tokens):\n",
        "  return [t for t in tokens\n",
        "          if not t.startswith(\"http://\")\n",
        "          and not t.startswith(\"https://\")\n",
        "        ]\n",
        "\n",
        "# Tokenizing the text\n",
        "def tokenize(text, lowercase=True, tweet=False):\n",
        "  if lowercase:\n",
        "        text = text.lower()\n",
        "  if tweet:\n",
        "        return TWEET_TOKENIZER(text)\n",
        "  else:\n",
        "        return WORD_TOKENIZER(text)\n",
        "\n",
        "# Reducing the number of repeated words\n",
        "def stem(tokens):\n",
        "  return [STEMMER.stem(token) for token in tokens]\n",
        "\n",
        "# Removing stopwords\n",
        "def remove_stopwords(tokens, stopwords=None):\n",
        "  if stopwords is None:\n",
        "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "  return [ token for token in tokens if token not in stopwords]\n",
        "\n",
        "# Feature reduction, graphing only the root words\n",
        "def lemmatize(tokens):\n",
        "    lemmas = []\n",
        "    for token in tokens:\n",
        "        if isinstance(token, str):\n",
        "            lemmas.append(LEMMATIZER.lemmatize(token))\n",
        "        else:\n",
        "            lemmas.append(LEMMATIZER.lemmatize(*token))\n",
        "    return lemmas\n",
        "\n",
        "# Removing punctuation\n",
        "def remove_punctuation(tokens,\n",
        "                       strip_mentions=False,\n",
        "                       strip_hashtags=False,\n",
        "                       strict=False):\n",
        "    tokens = [t for t in tokens if t not in string.punctuation]\n",
        "    if strip_mentions:\n",
        "        tokens = [t.lstrip('@') for t in tokens]\n",
        "    if strip_hashtags:\n",
        "        tokens = [t.lstrip('#') for t in tokens]\n",
        "    if strict:\n",
        "        cleaned = []\n",
        "        for t in tokens:\n",
        "            cleaned.append(\n",
        "                t.translate(str.maketrans('', '', string.punctuation)).strip())\n",
        "        tokens = [t for t in cleaned if t]\n",
        "    return tokens\n",
        "\n",
        "# Removing words less than 2 characters\n",
        "def remove_single_words(tokens):\n",
        "  goodwords = []\n",
        "  for a_feature in tokens:\n",
        "    if len(a_feature) > 1:\n",
        "      goodwords.append(a_feature)\n",
        "  return goodwords\n",
        "\n",
        "# Filtering out certain parts of speech\n",
        "def filter_part_of_speech(tokens, tagger=nltk.tag.PerceptronTagger().tag, parts_of_speech=None):\n",
        "  words = tokens\n",
        "  tags = tagger(words)\n",
        "  tokens = []\n",
        "  for tag in tags:\n",
        "      if parts_of_speech is None or tag[1] in parts_of_speech:\n",
        "        if tag[0] not in tokens:\n",
        "          tokens.append(tag[0])\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "ZyYNXNt7eXCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating 'text_preprocessing' function to hold all helper functions above\n",
        "def text_preprocessing(text):\n",
        "  tokens = tokenize(text, lowercase=True, tweet=True)\n",
        "  tokens = filter_part_of_speech(tokens, parts_of_speech=['NNP', 'NN', 'NNS', 'NNPS', # Nouns\n",
        "                                                            'JJ', 'JJR', 'JJS', # Adjectives\n",
        "                                                            'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']) #Verbs\n",
        "  tokens = removeURL(tokens)\n",
        "  tokens = remove_stopwords(tokens, stopwords = stopwords_set)\n",
        "  tokens = remove_punctuation(tokens, strip_mentions=True, strip_hashtags=True)\n",
        "  tokens = lemmatize(tokens)\n",
        "  tokens = remove_single_words(tokens)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "PTxltIpxXDcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting and expanding the list of stopwords\n",
        "stopwords_set = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "stopwords_set.add('rt')\n",
        "stopwords_set.add(\"'s\")\n",
        "stopwords_set.add('...')\n",
        "stopwords_set.add('..')\n",
        "stopwords_set.add(':/')"
      ],
      "metadata": {
        "id": "wpYlgtd2iBBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Identifying Unique Words**"
      ],
      "metadata": {
        "id": "r-Hl1lFEibyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in the json file again for more iteration\n",
        "json_file = open(FILE_PATH, 'r')"
      ],
      "metadata": {
        "id": "K9bzmJ22gxfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dictionary of unique words, retrieved after processing the data\n",
        "\n",
        "# Creating empty dictionary\n",
        "unique_words = {}\n",
        "\n",
        "# Iterating through the json file\n",
        "for i, atweet in enumerate(json_file):\n",
        "    # Counting progress\n",
        "    if i % 10000 == 0:\n",
        "      print(i)\n",
        "    tweet_json = json.loads(atweet)\n",
        "    text = tweet_json['full_text']\n",
        "    # Natural language preprocessing, using the helper functions from above\n",
        "    tokens = text_preprocessing(text)\n",
        "    # Adding processed words to 'unique_words' dictionary\n",
        "    for aword in tokens:\n",
        "        if aword in unique_words:\n",
        "            unique_words[aword] += 1\n",
        "        if aword not in unique_words:\n",
        "            unique_words[aword] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8t6KhEug9nq",
        "outputId": "3ebb9ac8-b7ed-4246-b750-824073be25b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n",
            "160000\n",
            "170000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soLQYIFch0xK",
        "outputId": "ee44cbcc-1e31-4bc5-d477-d6cfbd69e35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78327"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sorted list of words\n",
        "sorted_counts = sorted(unique_words.items(), key=lambda item: item[1], reverse=True)\n",
        "sorted_words = [word for word, count in sorted_counts]\n",
        "# Checking the top 10 words in the unique word list\n",
        "sorted_words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyzJ4SU3izW_",
        "outputId": "e9dc3306-bbaa-4866-d068-cea591cfc542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nike',\n",
              " 'adidas',\n",
              " 'sneakerscouts',\n",
              " 'eneskanter',\n",
              " 'xbox',\n",
              " 'available',\n",
              " 'day',\n",
              " 'air',\n",
              " 'china',\n",
              " 'kingjames']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the word counts for the major brands\n",
        "print(\"Nike:\", unique_words[\"nike\"])\n",
        "print(\"Adidas:\", unique_words[\"adidas\"])\n",
        "print(\"Lululemon:\", unique_words[\"lululemon\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWu3FN0ejGob",
        "outputId": "cab697bb-8f6b-459c-9c79-d57dae74d774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nike: 102691\n",
            "Adidas: 36256\n",
            "Lululemon: 6226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a set of words to include in the semantic network map\n",
        "words_to_include = set()\n",
        "word_count = 0\n",
        "\n",
        "# Selecting words used over 250 times to add to total number of unique words\n",
        "for aword in unique_words:\n",
        "    if unique_words[aword] > 250:\n",
        "        word_count += 1\n",
        "        words_to_include.add(aword)"
      ],
      "metadata": {
        "id": "G7leII80khul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of filtered words to include\n",
        "print(len(words_to_include))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjWdnwDTk4GN",
        "outputId": "5fec2771-07eb-42d7-c391-bb4f923eb29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing number of words to include to intial number of unique words\n",
        "len(words_to_include)/len(unique_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGhKXsARb7Te",
        "outputId": "efe8651a-fab7-458d-a726-83f68dabef3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01163072759074138"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating the Graph**"
      ],
      "metadata": {
        "id": "v9-cpEsRlCA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in the json file again for more iteration\n",
        "json_file = open(FILE_PATH, 'r')"
      ],
      "metadata": {
        "id": "6ZCT8jv1lPrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepraring a graph\n",
        "Semantic_Graph = nx.Graph()"
      ],
      "metadata": {
        "id": "w_nDoEVqlQJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the graph, this is roughly the same as for the Twitter mentions graph\n",
        "\n",
        "# Iterating through the json file\n",
        "for i, atweet in enumerate(json_file):\n",
        "    # Tracking progress\n",
        "    if i % 10000 == 0:\n",
        "      print(i)\n",
        "    tweet_json = json.loads(atweet)\n",
        "    text = tweet_json['full_text']\n",
        "    # Cleaning the text with the helper functions\n",
        "    tokens = text_preprocessing(text)\n",
        "    nodes = [t for t in tokens if t in words_to_include]\n",
        "    if len(nodes) > 0:\n",
        "      # Looking for cooccurences of 2\n",
        "      cooccurrences = itertools.combinations(nodes, 2)\n",
        "      # Iterating through all the combinations\n",
        "      for c in cooccurrences:\n",
        "        if c[0] != c[1]:\n",
        "          # Adding the tuples of words as edges to the graph\n",
        "          if Semantic_Graph.has_edge(c[0], c[1]):\n",
        "            # Incrementing the weight if the edge exists\n",
        "            Semantic_Graph[c[0]][c[1]]['weight'] += 1\n",
        "          else:\n",
        "            # Adjusting the weight if the edge doesn't exist\n",
        "            Semantic_Graph.add_edge(c[0], c[1], weight=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc7qkXKhlVkV",
        "outputId": "1ac01e83-bb11-4864-ca3f-6cfc8ea93407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n",
            "160000\n",
            "170000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking number of nodes and edges in directional graph\n",
        "graph_summary_stats(G = Semantic_Graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnr9kYEvlnEp",
        "outputId": "f5e57031-d689-4ec0-9c2e-d09e4adfc2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "##### Graph Summary #####\n",
            "number of nodes: 911\n",
            "number of edges: 208165\n",
            "\n",
            "nodes: ['nike', \"women's\", 'air', 'uptempo', 'white', 'yellow', 'available', 'footlocker', 'sneakerscouts', 'adidas', 'lasership', 'stealing', 'work', 'home', 'alert', 'next', 'collab', 'dropping', 'ad', 'space', 'low', 'snipes_usa', 'snkrs', 'get', 'nikebasketball', 'puma', 'stock', 'partnership', 'helped', 'grow', 'etnow', 'team', 'release', 'jordan', 'real', 'support', 'friend', 'family', 'sick', 'kaya_alexander5', 'nikestore', 'sneakeradmirals', 'awesome', 'pair', 'lot', 'wait', 'dress', 'game', 'jumpman23', 'usnikefootball', 'usarmy', 'britisharmy', 'cnn', 'wheeloffortune', 'bloombergradio', 'wbpictures', 'disneystudios', 'wgci', 'hot97', 'v103', 'tmz', 'harveylevintmz', 'instagram', 'ebay', 'amazon', 'abc', 'abc7chicago', 'chicago_police', 'nypdnews', 'usairforce', 'usmc', 'usnavy', 'royalnavy', 'royalairforce', 'jack', 'finkd', 'priscillachanz', 'business', 'fbi', 'beccadiamondxx', 'potus', 'vp', 'drbiden44', 'bet', 'max', 'japan', 'ht', 'dunk', 'beautiful', 'fuck', 'working', 'sizeofficial', 'adidasus', 'adidasoriginals', 'look', 'problem', 'wearing', 'say', 'drop', 'time', 'vapormax', 'flyknit', 'royal', 'finishline', 'young', 'thetraeyoung', 'much', 'people', 'like', 'nicekicks', 'snkr_twitr', 'iamtmcii', 'good', 'edition', 'global', 'sport', 'week', 'take', 'place', 'black', 'lol', 'apple', 'think', 'corporation', 'care', 'latest', 'underarmour', 'deal', 'run', 'company', 'jersey', 'win', 'guy', 'see', 'way', 'keep', 'play', 'top', 'going', 'year', 'thank', 'great', 'getting', 'started', 'moment', 'connected', 'show', 'understand', \"they're\", 'making', 'tweet', 'want', 'others', 'word', 'kingjames', 'start', 'dude', 'blazer', 'suede', 'red', 'need', 'sneaker', 'day', 'color', 'style', 'code', 'date', 'price', 'sneakerhead', 'fashion', 'yes', 'know', 'free', 'used', 'celebrating', 'birthday', 'discount', 'item', 'thanks', 'given', 'something', 'trying', 'seen', 'issue', 'hand', 'let', 'make', 'sure', 'love', 'school', 'student', 'buy', 'quality', 'everyone', 'job', 'theestallion', 'thee', 'app', 'morning', 'history', 'step', 'go', 'shoe', 'part', 'facility', 'forum', 'mid', 'bot', 'sold', 'summit', 'bright', 'wolf', 'grey', 'hey', 'cool', 'pay', 'dropped', 'exclusive', 'access', 'long', 'member', 'got', 'account', 'brand', 'new', 'customer', 'bought', 'blue', 'month', 'light', 'cocacola', 'turn', 'join', 'please', 'city', 'lime', 'glow', 'kdtrey5', 'coach', 'sponsor', 'use', 'steal', 'package', 'delivery', 'put', 'left', 'le', 'minute', 'delivered', 'lululemon', 'bill', 'happy', 'friday', 'strong', 'weekend', 'jacket', 'deep', \"we're\", 'giving', 'store', 'head', 'wanted', 'hi', 'running', 'force', 'email', 'thing', \"i'm\", 'woman', 'god', 'service', 'idea', 'night', 'gonna', 'waiting', 'old', 'son', 'first', 'tv', 'espn', 'appreciate', 'wnba', 'help', 'change', 'move', 'kicksonfire', 'bro', 'best', 'custom', 'candace_parker', 'leader', 'human', 'right', 'order', 'congrats', 'manager', 'justdoit', 'pixel', 'se', 'gear', 'partner', 'wild', 'retail', 'http', 'second', 'season', 'yeah', 'bad', 'one', 'ice', 'soccer', 'ask', 'thought', 'kit', 'lfc', 'line', 'match', 'sock', 'york', 'looking', 'man', 'many', 'size', 'last', 'chance', 'said', 'wow', 'club', 'shop', 'shirt', 'law', 'tell', \"he's\", 'remember', 'decided', 'campaign', 'link', 'read', 'story', 'today', 'nikenyc', 'girl', 'point', 'smh', 'ni', 'continue', 'stay', 'boot', 'camp', 'swoosh', 'medium', 'em', 'hit', 'nice', 'add', 'tried', 'different', 'product', 'stop', 'adidasrunning', 'adidasfballus', 'adidashoops', 'htt', 'talking', 'shit', 'several', 'money', 'actual', 'virtual', 'event', 'fly', 'israel', 'glad', 'snkrfrkrmag', 'atmos_usa', 'theshoegame', 'üôèüèº', 'ticket', 'sale', 'la', 'tomorrow', 'gatorade', 'ordered', 'came', 'site', 'thesocialstatus', \"that's\", 'starting', 'dick', 'detail', 'yall', 'big', 'wtf', 'incredible', 'hippie', 'foot', 'fontanka', 'pink', 'find', 'kotd', 'yoursneakersaredope', 'kind', 'safe', 'exploring', 'lebron', 'james', 'college', 'wish', 'athlete', 'early', 'video', 'neutral', 'olive', 'travis', 'kick', 'fix', 'fan', 'wear', 'total', 'classic', 'green', 'selling', 'special', 'check', 'icon', 'able', 'follow', 'twitter', 'sb', 'box', 'football', 'believe', 'done', 'community', 'chicago', 'try', 'amazing', 'luck', 'life', 'short', 'holiday', 'face', 'talk', 'buying', 'pant', 'boy', 'pushed', 'send', 'ig', 'academy', 'woke', 'hoodie', 'favorite', 'orange', 'congratulation', 'feel', 'social', 'message', 'supply', 'crazy', 'tho', 'corporate', 'become', 'model', 'rest', 'world', 'pepsi', 'üôåüèΩ', 'online', 'paid', 'shipping', 'stuff', 'found', 'bring', 'back', 'christmas', 'uniform', 'report', 'high', 'forced', 'chinese', 'shut', 'guess', 'fire', 'watch', 'nikegolf', 'ball', 'nikefootball', 'pathetic', 'made', 'court', 'retro', 'modern', 'purchase', 'seeing', 'program', 'phil', 'knight', 'street', 'university', 'name', 'image', 'rule', 'official', 'clean', 'chicksinkicks2', 'shot', 'hour', 'soleguru', 'welcome', 'converse', 'slave', 'labor', 'clothing', \"can't\", 'number', 'gift', 'suck', 'biggest', 'person', 'innovation', 'fam', 'beiberlove69', 'stand', 'mean', 'wrong', 'type', 'question', 'original', 'come', 'wonder', 'speak', 'update', 'cause', 'website', 'triple', 'better', 'sell', 'im', 'purple', 'dawn', 'fedex', 'worst', 'fit', 'profit', 'called', 'consumersfirst', 'dm', 'took', 'design', 'example', 'kanyewest', 'cop', 'collection', 'content', 'super', 'dope', 'lost', 'ups', 'ship', 'walmart', 'refund', 'mind', 'logo', 'pack', 'heard', 'give', 'card', 'fun', 'true', 'mine', \"i've\", 'hope', 'meet', 'pick', 'gotta', 'dollar', 'american', 'fresh', 'state', 'boost', 'tech', 'side', 'griffey', 'future', 'controlled', 'return', 'netflix', 'present', 'nikeservice', 'saying', 'draw', 'passing', 'post', 'someone', 'lexxdaturtle', 'charger', 'thinking', 'commercial', 'vadriano2000', 'full', 'happen', 'damn', 'wanna', 'whole', 'anyone', 'baby', 'kid', 'hard', 'huge', 'perfect', 'hell', 'prize', 'taking', 'sorry', 'unlvfootball', 'uniswag', 'marketing', 'asking', 'nfl', 'chose', 'fact', 'nothing', 'raffle', 'leading', 'player', \"let's\", 'men', 'dear', 'clothes', 'missing', 'little', 'course', 'opening', 'ok', 'public', 'photo', 'end', 'child', 'hold', 'seems', 'sound', 'using', 'jamarrobrown', 'book', 'navy', 'nikesb', 'saw', 'loved', 'hear', 'ya', 'dream', 'as', 'nft', 'gold', 'collaboration', 'anything', 'sent', 'hate', 'playing', 'exec', 'call', 'reason', 'celebrate', 'newbalance', 'supporting', 'boston', 'least', 'share', 'mcdonalds', 'trash', 'went', 'yo', 'live', 'set', 'coming', 'solefed', 'apparel', 'anniversary', 'excited', 'midnight', 'china', 'employee', 'told', 'pic', 'jadendaly', 'target', 'fucking', 'worker', 'received', 'opportunity', 'boycott', 'tonight', 'listen', 'bit', 'matter', 'michael', 'trvisxx', 'nba', 'celtic', 'sign', 'country', 'meeting', 'proud', 'including', 'goal', 'canada', 'final', 'üôèüèæ', 'happened', 'lsoshipping', 'yesterday', 'agree', 'launch', 'basketball', 'ready', 'dirtydetty9381', 'nfts', 'phone', 'yeezy', 'list', 'impossibleisnothing', 'rock', 'speaking', 'donaldjtrumpjr', 'comment', 'maniere_usa', 'fast', 'kaepernick7', 'joshuajhan', 'xbox', 'december', 'bag', 'oh', 'dark', 'cosmic', 'unity', 'everything', 'solelinks', 'miss', 'introducing', 'experience', 'announced', 'act', 'foamposite', 'calling', '_talkswithtj', 'adizero', 'runningshoesgur', 'runningshoes', 'festive', 'signed', 'contract', 'fuel', 'credit', 'major', 'holy', 'inspire', 'reebok', 'teamcanada', 'impossible', 'slavery', 'inspired', 'open', 'project', 'olympics', 'create', 'spidadmitchell', 'respect', 'lmao', 'league', 'patta_nl', 'news', 'recent', 'america', 'jdsports', 'culture', 'enter', 'owner', 'market', 'eliudkipchoge', 'grail', 'boardroom', 'action', 'brilliant', 'blocked', 'djbluiz', 'changing', 'baseball', 'weareivypark', 'turtlepace5', 'shame', 'november', 'uno', 'region', 'deezle148', '210gotkickz', 'voice', 'on-court', 'repjimbanks', 'joebiden', 'billboard', 'digital', 'copping', 'xinjiang', 'david', 'xbox20', 'metaverse', 'analyst', 'entire', 'aaron', 'justintrudeau', 'relationship', 'king', 'de', 'dashiexp', 'yooo', 'imagine', 'import', 'banned', 'web', 'twotimesprime', 'uyghur', 'mindless_bmd', 'ayeeeee', 'postseason', 'statefarm', 'respond', 'ban', 'sneakerhd84', 'senator', 'centre', 'entering', 'beyonce', 'nov', 'backpack', 'solesavy', 'giannis_an34', 'twelve', 'thunder', 'hero', 'roblox', 'crater', 'donovan', 'mitchell', 'austinekeler', 'Ô∏ègiveaway', 'peo', 'michael_fabiano', 'slam', 'yardrunner', 'generation', 'easportsfifa', 'lied', 'heartbroken', 'acquired', 'duffel', 'taeyong', 'lazylionsnft', 'sephora', 'xboxsweepstakes', 'hyperkin', 'auxgod_', 'stern', 'bred', 'realunogame', 'plane', 'ingloriousguido', 'eneskanter', 'kanter', 'malcolmjackso20', 'recognizes', 'rtfktstudios', 'ene', 'meta', 'enduyghurforcedlabor', 'eth', 'uninterrupted', 'prevention', 'boredapeyc', 'garcons', 'brooklynsown90', 'graduation', 'scctradingcards', 'topps', 'virgil', 'lagalaxy', 'psg_english', 'elizabeth_that', 'rodgers', 'richsignorelli', 'techinsider', \"abloh's\", 'sen', 'nikeland', 'funneled', 'throne', 'nba_newyork', 'pre-day', 'enesfreedom', 'clonex', 'rtfkt', 'invsblefriends', 'footydotcom_', \"footy's\", 'zaptio', 'benitopagotto', 'spacerunnersnft', 'ronwyden', 'septe', 'maybes']\n",
            "\n",
            "neighbors of adidas: ['available', 'puma', 'stock', 'partnership', 'helped', 'grow', 'nike', 'real', 'get', 'support', 'friend', 'family', 'adidasus', 'adidasoriginals', 'look', 'problem', 'wearing', 'say', 'drop', 'young', 'thetraeyoung', 'much', 'people', 'like', 'lol', 'deal', 'black', 'run', 'company', 'thank', 'great', 'team', 'getting', 'started', 'dude', 'red', 'need', 'jersey', 'yes', 'start', 'know', 'free', 'used', 'history', 'step', 'play', 'forum', 'mid', 'bot', 'sold', 'bought', 'pair', 'blue', 'month', 'light', 'please', 'next', 'city', 'long', 'beautiful', 'sneaker', 'love', 'new', 'grey', 'year', 'wanted', 'thanks', 'service', 'shoe', 'keep', 'idea', 'night', 'gonna', 'human', 'right', 'brand', 'make', 'sure', 'gear', 'see', 'got', 'one', 'good', 'day', 'top', 'trying', 'law', 'tell', 'let', \"he's\", 'think', 'dropping', 'today', 'way', 'smh', 'snkr_twitr', 'adidasrunning', 'adidasfballus', 'adidashoops', \"we're\", 'glad', 'em', 'want', 'collab', 'tomorrow', 'man', 'show', 'site', 'wish', 'shop', 'underarmour', 'apple', 'awesome', 'first', 'athlete', 'size', 'fix', 'check', 'icon', 'able', 'believe', 'early', 'done', 'home', 'kit', 'follow', 'instagram', 'http', 'morning', 'try', 'amazing', 'luck', 'help', 'life', 'fan', 'buying', 'academy', 'shirt', 'woke', 'order', 'wait', 'online', 'fire', 'work', 'watch', 'boy', 'looking', 'fly', 'court', 'season', 'retro', 'modern', 'time', 'store', 'purchase', 'official', 'face', 'win', 'guess', 'total', 'shot', 'tweet', 'hour', 'sale', 'price', 'clothing', 'question', 'original', 'program', 'point', 'world', 'better', 'hey', 'going', 'im', 'big', 'thought', 'dm', 'welcome', 'many', 'design', 'example', 'kanyewest', 'mind', 'ordered', 'mine', \"i've\", \"i'm\", 'old', 'head', 'hope', 'meet', 'pick', 'take', 'care', 'gotta', 'find', 'state', 'white', 'boost', 'tech', 'side', 'give', 'future', 'controlled', 'return', 'passing', 'post', 'thinking', 'commercial', 'guy', 'weekend', 'wanna', 'ask', 'girl', 'wild', 'card', 'prize', 'working', 'seen', 'fun', 'collection', \"that's\", 'nice', 'sell', 'college', 'move', 'several', 'style', 'feel', 'sock', 'dress', 'hoodie', \"women's\", 'pant', 'lasership', 'delivered', 'package', 'customer', 'saying', 'money', 'waiting', 'actual', 'cocacola', 'nft', 'favorite', 'exec', 'sport', 'school', 'hard', 'bring', 'happy', 'birthday', 'last', 'newbalance', 'converse', 'supporting', 'boston', 'understand', 'sorry', 'everyone', 'put', 'dope', 'jacket', 'excited', 'share', 'coach', 'clean', \"let's\", 'buy', 'stop', 'video', 'something', 'thing', 'missing', 'made', 'green', 'player', 'tonight', 'super', 'high', 'talking', 'message', 'code', 'app', 'gold', 'collaboration', 'china', 'campaign', 'ad', 'asking', 'photo', 'ice', 'rule', 'sneakerhead', 'snipes_usa', 'running', 'fit', 'whole', 'color', 'minute', 'saw', 'release', 'bro', 'walmart', 'target', 'set', 'le', 'football', 'short', 'taking', 'stay', 'ready', 'using', 'reason', 'seems', 'nfts', 'pay', 'join', 'kick', 'impossibleisnothing', 'employee', 'best', 'found', 'different', 'jumpman23', 'nfl', 'nba', 'bag', 'full', 'stand', 'said', 'corporation', \"can't\", 'wear', 'product', 'second', 'game', 'ups', 'paid', 'pack', 'phone', 'lost', 'hell', 'website', 'pic', 'send', 'retail', 'kid', 'fucking', 'sick', 'mean', 'perfect', 'happen', 'shipping', 'worst', 'shit', 'suck', 'speak', 'uniform', 'someone', 'crazy', 'announced', 'cool', 'live', 'street', 'classic', 'huge', 'cause', 'adizero', 'runningshoesgur', 'runningshoes', 'week', 'back', 'part', 'canada', 'public', 'come', 'opportunity', 'god', 'kind', 'box', 'call', 'matter', 'line', 'bit', 'others', 'twitter', 'inspire', 'reebok', 'gatorade', 'kotd', 'yoursneakersaredope', 'safe', 'took', 'congrats', 'email', 'use', 'lot', 'discount', 'go', 'bad', 'celebrate', 'change', 'impossible', 'nothing', 'remember', 'name', 'anything', 'match', 'orange', 'member', 'experience', 'exclusive', 'went', 'goal', 'congratulation', 'turn', 'amazon', 'proud', 'add', 'number', 'damn', 'true', 'basketball', 'giving', 'sponsor', 'clothes', 'soccer', 'link', 'ok', 'course', 'open', 'nikebasketball', 'woman', 'enter', 'corporate', 'global', 'fedex', 'happened', 'delivery', 'yeezy', 'steal', 'stuff', 'hand', 'refund', 'wtf', 'nikestore', 'kdtrey5', 'owner', 'date', 'detail', 'ig', 'social', 'medium', 'low', 'quality', 'apparel', 'blocked', 'edition', 'making', 'hi', 'marketing', 'tv', 'business', 'mcdonalds', 'selling', 'foot', 'virtual', 'seeing', 'yo', 'üôåüèΩ', 'lmao', 'called', 'content', 'dream', 'pink', 'rock', 'everything', 'comment', 'ball', 'november', 'footlocker', 'story', 'ni', 'partner', 'gift', 'son', 'unity', 'uno', 'xbox', 'tho', 'news', 'alert', 'pepsi', 'market', 'recent', 'country', 'tried', 'trash', 'read', 'community', 'club', 'book', 'holiday', 'type', 'little', 'become', 'account', 'as', 'innovation', 'boot', 'brilliant', 'üôèüèº', 'special', 'report', 'sneakeradmirals', 'end', 'sound', 'calling', 'chose', '_talkswithtj', 'told', 'nikenyc', 'respect', 'item', 'issue', 'came', 'lululemon', 'anyone', 'james', 'vp', 'fuck', 'xbox20', 'anniversary', 'ebay', \"they're\", 'neutral', 'celebrating', 'coming', 'cop', 'inspired', 'launch', 'wrong', 'list', 'aaron', 'wow', 'fresh', 'la', 'king', 'ticket', 'signed', 'nicekicks', 'iamtmcii', 'beiberlove69', 'including', 'fact', 'word', 'air', 'event', 'dashiexp', 'yooo', 'sent', 'culture', 'baby', 'yall', 'logo', 'lime', 'yeah', 'jack', 'fam', 'candace_parker', 'least', 'model', 'hold', 'holy', 'credit', 'america', 'left', 'jordan', 'force', 'american', 'changing', 'fashion', 'wnba', 'michael', 'latest', 'hit', 'job', 'sizeofficial', 'banned', 'received', 'israel', 'men', 'uyghur', 'slave', 'labor', 'region', 'wonder', 'miss', 'person', 'appreciate', 'billboard', 'ban', 'dropped', 'exploring', 'dear', 'netflix', 'navy', 'espn', 'royal', 'purple', 'draw', 'space', 'ship', 'summit', 'chance', 'child', 'place', 'given', 'olympics', 'worker', 'playing', 'starting', 'weareivypark', 'beyonce', 'forced', 'supply', 'sign', 'entering', 'bet', 'oh', 'introducing', 'heard', 'contract', 'baseball', 'dick', 'update', 'yesterday', 'nov', 'continue', 'decided', 'solelinks', 'league', 'theestallion', 'cnn', 'moment', 'talk', 'final', 'stealing', 'major', 'max', 'statefarm', 'christmas', 'student', 'fast', 'snkrs', 'image', 'digital', 'eliudkipchoge', 'dark', 'hate', 'create', 'sb', 'rest', 'dunk', 'knight', 'chicago', 'triple', 'spidadmitchell', 'phil', 'dollar', 'relationship', 'ya', 'pathetic', 'leader', 'pushed', 'hear', 'raffle', 'access', 'agree', 'university', 'action', 'donovan', 'mitchell', 'friday', 'austinekeler', 'Ô∏ègiveaway', 'respond', 'peo', 'charger', 'michael_fabiano', 'shut', 'atmos_usa', 'leading', 'deep', 'chinese', 'kicksonfire', 'bill', 'strong', 'üôèüèæ', 'solefed', 'imagine', 'incredible', 'generation', 'easportsfifa', 'kingjames', 'entire', 'biggest', 'custom', 'present', 'japan', 'opening', 'project', 'taeyong', 'se', 'hero', 'xboxsweepstakes', 'hyperkin', 'glow', 'act', 'travis', 'roblox', 'plane', 'nikefootball', 'bright', 'speaking', 'turtlepace5', 'grail', 'boycott', 'ingloriousguido', 'shame', 'loved', 'lexxdaturtle', 'deezle148', 'finishline', 'celtic', 'blazer', 'heartbroken', 'meeting', 'ht', 'usnikefootball', 'slam', 'swoosh', 'recognizes', 'soleguru', 'jdsports', 'manager', 'htt', 'eneskanter', 'nikesb', 'nikeservice', 'justdoit', 'kanter', 'realunogame', 'giannis_an34', 'solesavy', 'sephora', 'lfc', 'uniswag', 'lagalaxy', 'topps', 'profit', 'listen', 'boredapeyc', 'kaepernick7', 'york', 'pixel', 'december', 'fbi', 'rodgers', 'yellow', 'meta', 'backpack', 'tmz', 'copping', 'dawn', 'suede', 'trvisxx', 'centre', 'richsignorelli', 'lied', 'techinsider', 'analyst', 'david', 'web', 'camp', 'lebron', 'usnavy', 'usmc', 'usarmy', 'usairforce', '210gotkickz', 'metaverse', 'eth', 'twotimesprime', 'flyknit', 'acquired', 'rtfktstudios', 'thunder', 'kaya_alexander5', 'facility', 'jadendaly', 'abc', 'vadriano2000', 'senator', 'midnight', 'voice', 'britisharmy', 'wheeloffortune', 'bloombergradio', 'wbpictures', 'disneystudios', 'wgci', 'hot97', 'v103', 'harveylevintmz', 'etnow', 'abc7chicago', 'chicago_police', 'nypdnews', 'royalnavy', 'royalairforce', 'finkd', 'priscillachanz', 'beccadiamondxx', 'potus', 'connected', 'drbiden44', 'import', 'olive', 'foamposite', 'lazylionsnft', 'de', 'nikeland', 'clonex', 'nikegolf', 'boardroom', 'joebiden', 'scctradingcards', 'psg_english', 'sen', 'snkrfrkrmag', 'invsblefriends', 'maniere_usa', 'thee', 'stern', 'duffel', 'benitopagotto', 'rtfkt', 'funneled', 'fuel', 'bred', 'graduation', 'slavery', 'maybes', 'on-court', 'jamarrobrown', 'thesocialstatus']\n",
            "neighbors of nike: [\"women's\", 'air', 'uptempo', 'white', 'yellow', 'available', 'footlocker', 'sneakerscouts', 'lasership', 'stealing', 'work', 'home', 'alert', 'next', 'collab', 'dropping', 'snkrs', 'get', 'nikebasketball', 'puma', 'stock', 'partnership', 'helped', 'grow', 'adidas', 'etnow', 'team', 'release', 'jordan', 'sick', 'lot', 'wait', 'dress', 'usarmy', 'britisharmy', 'cnn', 'wheeloffortune', 'bloombergradio', 'wbpictures', 'disneystudios', 'wgci', 'hot97', 'v103', 'tmz', 'harveylevintmz', 'instagram', 'ebay', 'amazon', 'abc', 'abc7chicago', 'chicago_police', 'nypdnews', 'usairforce', 'usmc', 'usnavy', 'royalnavy', 'royalairforce', 'jack', 'finkd', 'priscillachanz', 'business', 'fbi', 'beccadiamondxx', 'potus', 'vp', 'drbiden44', 'bet', 'ad', 'max', 'japan', 'snipes_usa', 'ht', 'dunk', 'beautiful', 'sizeofficial', 'time', 'vapormax', 'flyknit', 'royal', 'finishline', 'jumpman23', 'sneakeradmirals', 'nicekicks', 'snkr_twitr', 'iamtmcii', 'look', 'good', 'black', 'apple', 'think', 'people', 'corporation', 'care', 'latest', 'underarmour', 'working', 'win', 'guy', 'see', 'way', 'keep', 'play', 'say', 'top', 'going', 'year', 'moment', 'connected', 'show', 'understand', \"they're\", 'making', 'tweet', 'want', 'others', 'space', 'low', 'kingjames', 'edition', 'start', 'blazer', 'suede', 'getting', 'celebrating', 'birthday', 'discount', 'item', 'thanks', 'given', 'something', 'trying', 'seen', 'issue', 'hand', 'go', 'shoe', 'part', 'facility', 'support', 'summit', 'bright', 'wolf', 'grey', 'cocacola', 'turn', 'join', 'problem', 'lime', 'glow', 'kdtrey5', 'new', 'coach', 'sponsor', 'use', 'company', 'steal', 'package', 'delivery', 'put', 'left', 'le', 'minute', 'delivered', 'week', 'deep', 'know', 'thing', \"i'm\", 'woman', 'day', 'god', 'waiting', 'red', 'let', 'order', 'congrats', 'customer', 'manager', 'justdoit', 'force', 'pixel', 'se', 'happy', 'partner', 'wild', 'retail', 'http', 'second', 'season', 'yeah', 'bad', 'lol', 'ice', 'soccer', 'store', 'ask', 'thought', 'kit', 'lfc', 'real', 'line', 'match', 'sock', 'york', 'game', 'custom', 'jersey', 'man', 'many', 'pair', 'size', 'last', 'chance', 'said', 'sold', 'wow', 'club', 'shop', 'shirt', 'please', 'remember', 'app', 'nikenyc', 'girl', 'point', 'blue', 'night', 'ni', 'love', 'swoosh', 'htt', 'today', 'several', 'job', 'make', 'money', 'actual', 'virtual', 'event', 'take', 'link', 'israel', 'right', 'snkrfrkrmag', 'atmos_usa', 'theshoegame', 'üôèüèº', 'great', 'nikestore', 'gatorade', 'dick', 'sure', 'detail', 'incredible', 'global', 'brand', 'hippie', 'light', 'fontanka', 'pink', 'need', 'medium', 'city', 'exploring', 'neutral', 'olive', 'stop', 'giving', 'travis', 'kick', 'buy', 'total', 'classic', 'green', 'college', 'started', 'sport', 'story', 'check', 'sb', 'box', 'sneaker', 'thank', 'pant', 'boy', 'got', 'pushed', 'send', 'hoodie', 'favorite', 'color', 'orange', 'product', 'corporate', 'become', 'model', 'rest', 'world', 'pepsi', 'üôåüèΩ', 'shipping', 'found', 'bring', 'back', 'christmas', 'uniform', 'report', 'high', 'price', 'forced', 'chinese', 'shut', 'woke', 'best', 'nikegolf', 'ball', 'nikefootball', 'pathetic', 'made', 'big', 'able', 'seeing', 'program', 'purchase', 'school', 'luck', 'phil', 'knight', 'street', 'university', 'athlete', 'name', 'image', 'rule', 'chicksinkicks2', 'much', 'kaya_alexander5', 'soleguru', 'welcome', 'converse', 'holiday', 'slave', 'labor', \"can't\", 'number', 'gift', 'suck', 'innovation', 'fam', 'beiberlove69', 'quality', 'stand', 'mean', 'wrong', 'wish', 'type', 'come', 'em', 'wonder', 'cause', 'website', 'selling', 'lebron', 'triple', 'sell', 'run', 'purple', 'dawn', 'fan', 'fedex', 'worst', 'help', 'foot', 'fit', 'profit', 'called', 'cop', 'believe', 'collection', 'content', 'super', 'dope', 'bro', 'lost', 'ups', 'service', 'ship', 'walmart', 'refund', 'awesome', 'logo', 'pack', 'fun', 'true', 'watch', 'looking', 'give', 'fuck', 'dollar', 'american', 'buying', 'shit', 'fresh', 'griffey', 'tell', 'netflix', 'campaign', 'present', 'add', 'draw', 'lexxdaturtle', 'gonna', 'charger', 'vadriano2000', 'full', 'community', 'one', 'ordered', 'happen', 'ig', 'nice', 'damn', 'paid', 'whole', 'appreciate', 'free', 'anyone', 'word', 'strong', 'baby', 'amazing', 'hell', 'mine', 'weekend', 'tried', 'unlvfootball', 'usnikefootball', 'uniswag', 'hi', 'marketing', 'month', 'done', 'theestallion', 'raffle', 'long', 'player', 'im', 'clothes', 'nothing', 'missing', 'speak', 'retro', 'little', 'fashion', 'sale', 'online', 'photo', 'follow', 'end', 'child', 'question', 'gear', 'nfl', 'first', 'place', 'seems', 'fire', 'icon', 'yes', 'nikeservice', 'book', 'navy', 'cool', 'nikesb', 'saw', 'loved', 'old', 'bought', 'talk', 'social', 'glad', 'pay', 'hard', 'try', 'fix', 'gold', 'wearing', 'anything', 'sent', 'hate', 'playing', 'call', 'yall', 'gotta', 'video', 'feel', 'deal', \"that's\", 'newbalance', 'took', 'hit', 'least', \"we're\", 'life', 'share', 'design', 'hey', 'mcdonalds', 'trash', 'dude', 'wear', 'went', 'yo', 'face', 'person', 'used', 'talking', 'better', 'reason', 'stuff', 'friday', 'set', 'coming', 'solefed', 'kicksonfire', 'son', 'apparel', 'anniversary', 'kid', 'excited', 'change', 'live', 'midnight', 'everyone', 'yoursneakersaredope', 'kotd', 'tomorrow', 'head', 'wanted', 'china', 'employee', 'told', 'crazy', 'came', 'shot', 'dream', 'clean', 'jamarrobrown', 'jadendaly', 'target', 'bill', 'fucking', 'find', 'style', 'opportunity', 'boycott', 'tv', 'commercial', 'running', 'state', 'fact', 'modern', 'football', 'listen', 'saying', 'michael', 'trvisxx', 'nba', 'celtic', 'including', 'meet', 'goal', 'sneakerhead', 'canada', 'someone', 'worker', 'move', 'young', 'final', 'opening', 'üôèüèæ', 'dropped', 'country', 'hope', 'site', 'men', 'agree', 'original', 'future', 'jacket', 'different', 'launch', 'exclusive', 'sign', 'course', 'basketball', 'academy', 'family', 'bot', 'taking', 'dirtydetty9381', 'ok', 'post', 'sorry', 'as', 'phone', 'member', 'thinking', 'guess', 'list', 'using', 'hour', 'supporting', 'drop', 'yesterday', 'donaldjtrumpjr', 'comment', 'maniere_usa', 'chicago', 'fast', 'kaepernick7', 'morning', 'ready', 'idea', 'joshuajhan', 'xbox', 'tho', 'adidasus', 'perfect', 'hear', 'december', 'kind', 'example', 'return', 'huge', 'dear', 'dark', 'wanna', 'asking', 'friend', 'cosmic', 'unity', 'official', 'miss', 'stay', 'special', 'dm', 'introducing', 'experience', 'thee', 'decided', 'short', 'access', 'everything', 'act', \"i've\", 'foamposite', 'date', 'calling', '_talkswithtj', 'like', 'festive', 'continue', 'read', 'fuel', 'credit', 'oh', 'hold', 'major', 'card', 'message', 'congratulation', 'twitter', 'holy', 'inspire', 'reebok', 'james', 'boston', 'student', 'email', 'espn', 'safe', 'biggest', 'nfts', \"he's\", 'camp', 'prize', 'la', 'inspired', \"let's\", 'wnba', 'open', 'court', 'project', 'olympics', 'pick', 'spidadmitchell', 'contract', 'leading', 'clothing', 'league', 'patta_nl', 'news', 'ya', 'early', 'meeting', 'boot', 'step', 'america', 'jdsports', 'culture', 'mid', 'side', 'create', 'announced', 'owner', 'market', 'wtf', 'eliudkipchoge', 'grail', 'received', 'solelinks', 'pic', 'tech', 'collaboration', 'brilliant', 'respect', 'adidasoriginals', 'update', 'djbluiz', 'changing', 'smh', 'baseball', 'weareivypark', 'bit', 'turtlepace5', 'account', 'celebrate', 'sound', 'mind', 'shame', 'bag', 'november', 'matter', 'region', 'happened', 'nft', 'uno', 'starting', 'blocked', 'recent', 'lmao', 'heard', 'signed', 'voice', 'on-court', 'repjimbanks', 'supply', 'joebiden', 'proud', 'billboard', 'lsoshipping', 'rock', 'boardroom', '210gotkickz', 'xinjiang', 'david', 'fly', 'controlled', 'history', 'lululemon', 'analyst', 'law', 'enter', 'deezle148', 'justintrudeau', 'digital', 'relationship', 'de', 'action', 'import', 'human', 'dashiexp', 'web', 'banned', 'twotimesprime', 'king', 'entire', 'tonight', 'kanyewest', 'uyghur', 'mindless_bmd', 'ayeeeee', 'boost', 'respond', 'copping', 'imagine', 'passing', 'consumersfirst', 'thesocialstatus', 'code', 'slavery', 'senator', 'entering', 'speaking', 'public', 'sneakerhd84', 'adidasrunning', 'impossible', 'leader', 'backpack', 'candace_parker', 'solesavy', 'exec', 'giannis_an34', 'twelve', 'ticket', 'hero', 'metaverse', 'roblox', 'yeezy', 'crater', 'yooo', 'adidashoops', 'slam', 'yardrunner', 'aaron', 'lied', 'heartbroken', 'nov', 'acquired', 'ban', 'postseason', 'lazylionsnft', 'chose', 'centre', 'sephora', 'hyperkin', 'auxgod_', 'stern', 'realunogame', 'xboxsweepstakes', 'mitchell', 'eneskanter', 'kanter', 'taeyong', 'recognizes', 'malcolmjackso20', 'bred', 'rtfktstudios', 'ene', 'thunder', 'plane', 'enduyghurforcedlabor', 'uninterrupted', 'forum', 'prevention', 'boredapeyc', 'generation', 'brooklynsown90', 'garcons', 'impossibleisnothing', 'scctradingcards', 'topps', 'duffel', 'virgil', 'meta', 'psg_english', 'ingloriousguido', 'elizabeth_that', 'eth', 'graduation', 'statefarm', 'rodgers', 'richsignorelli', 'techinsider', \"abloh's\", 'adidasfballus', 'easportsfifa', 'beyonce', 'nikeland', 'nba_newyork', 'teamcanada', 'runningshoes', 'sen', 'pre-day', 'enesfreedom', 'throne', 'rtfkt', 'invsblefriends', 'thetraeyoung', 'footydotcom_', \"footy's\", 'zaptio', 'clonex', 'benitopagotto', 'spacerunnersnft', 'ronwyden', 'funneled', 'septe']\n",
            "neighbors of lululemon: ['thank', 'bill', 'happy', 'friday', 'let', 'week', 'strong', 'great', 'weekend', 'jacket', 'nice', 'running', 'thanks', 'early', 'video', 'job', 'top', 'beautiful', 'follow', 'twitter', 'congratulation', 'feel', 'please', 'make', 'supply', 'brand', 'fashion', 'hey', 'order', 'paid', 'shipping', 'seen', 'stuff', 'biggest', 'life', 'new', 'person', 'event', 'got', 'good', 'friend', 'put', 'yall', 'everyone', 'kind', 'took', 'long', 'old', 'school', 'appreciate', 'love', 'awesome', 'need', 'give', 'place', 'card', 'buy', 'day', 'read', 'try', 'wish', 'store', 'get', 'ask', 'know', 'best', 'thing', 'ordered', 'question', 'customer', 'service', 'said', 'run', 'size', 'huge', 'return', 'pair', 'perfect', 'fit', 'tho', 'one', 'find', 'something', 'super', 'club', 'sponsor', 'product', 'leading', 'way', 'app', 'keep', 'lol', 'course', 'hold', 'wearing', 'mind', 'business', 'see', 'stay', 'collection', 'made', 'sound', 'uniform', 'time', 'season', \"i'm\", 'guy', 'think', 'bright', 'hear', 'ya', \"i've\", 'god', 'shop', 'chance', 'collaboration', 'im', 'pack', 'favorite', 'underarmour', 'deal', 'shirt', 'space', 'force', 'pant', 'look', 'discount', 'worker', 'show', 'anyone', 'received', 'package', 'say', 'delivered', 'help', 'yeah', 'sign', 'given', 'kid', 'country', 'tell', 'mean', 'meeting', 'smh', 'set', 'hell', 'many', 'employee', 'short', 'fix', 'home', 'work', 'take', 'shoe', 'coming', 'commercial', 'thought', 'hate', 'rock', 'come', 'gear', 'hit', 'people', 'man', 'speak', 'student', 'team', 'wow', 'site', 'last', 'night', 'oh', 'going', 'right', 'fan', 'told', 'money', 'wrong', 'line', 'point', 'real', 'better', 'website', 'lot', 'year', 'abc', 'want', 'boy', 'stop', 'join', 'community', 'tweet', 'hoodie', 'style', 'miss', 'university', 'saw', 'getting', 'morning', 'hope', 'talk', 'family', 'global', 'free', 'wanna', 'send', 'clothes', 'pink', 'go', 'tomorrow', 'boston', 'call', 'move', 'teamcanada', 'amazing', 'fam', 'share', 'world', 'today', 'high', 'bag', 'check', \"we're\", 'hour', 'experience', 'kick', 'working', 'fire', 'others', 'change', 'present', 'moment', 'remember', 'yellow', 'like', 'purchase', 'item', 'full', 'refund', 'le', 'minute', 'reason', 'woman', 'history', 'classic', 'create', 'list', 'respect', 'wear', 'company', 'fact', 'first', 'become', 'clothing', 'wait', 'bit', 'gift', 'ship', 'next', 'excited', 'speaking', 'ticket', 'part', 'using', 'found', 'including', 'recent', 'release', 'sell', 'sold', 'sent', 'nothing', 'anything', 'gonna', 'special', 'use', 'official', 'üôèüèº', 'code', 'opportunity', 'different', 'news', 'campaign', 'action', 'mine', 'calling', 'name', 'comment', 'fast', 'hard', 'start', 'ok', 'online', 'waiting', 'someone', 'phone', 'trying', 'support', 'message', 'custom', 'came', 'done', 'decided', 'email', 'went', 'end', 'connected', 'human', 'price', 'sure', 'saying', 'china', 'bought', 'game', 'blazer', \"women's\", 'white', 'black', 'grey', 'ready', 'nikegolf', 'word', 'match', 'clean', 'partnership', 'apparel', 'much', 'birthday', 'turn', 'heard', 'target', 'announced', 'yesterday', 'credit', 'partner', 'color', 'cool', 'social', 'changing', 'missing', 'edition', 'guess', 'starting', 'believe', 'type', 'opening', 'virtual', 'fun', 'helped', 'live', 'started', 'adidas', 'jumpman23', 'girl', 'ad', 'account', 'looking', 'nike', 'taking', 'converse', 'analyst', 'number', 'damn', 'yo', 'model', \"that's\", 'canada', 'athlete', 'raffle', 'prize', 'imagine', 'thinking', 'care', 'shame', 'report', 'buying', 'little', 'able', 'supporting', 'back', 'big', 'shit', 'gold', 'open', 'adidasoriginals', 'puma', 'corporation', 'sport', 'proud', 'leader', 'update', 'dropped', 'dollar', 'fedex', 'stand', 'luck', 'selling', 'hi', 'james', 'continue', 'welcome', 'month', 'head', 'act', 'available', 'asking', 'pay', 'happen', 'launch', 'agree', 'ig', 'blue', 'making', 'photo', 'story', 'used', 'matter', 'giving', 'date', 'sorry', 'inspired', 'issue', 'coach', 'inspire', 'centre', 'bad', 'link', 'total', 'side', 'potus', 'dark', 'state', 'baby', 'boycott', 'as', 'quality', 'celebrate', 'dear', 'woke', 'least', 'true', 'collab', 'city', 'understand', 'hand', 'american', 'fly', 'stock', 'book', 'pick', 'fresh', 'face', 'incredible', 'dude', 'men', 'foot', 'tried', 'respond', 'safe', 'pic', 'drop', 'problem', 'yes', 'delivery', 'win', 'congrats', 'loved', 'play', 'watch', 'wtf', 'talking', 'enter', 'dm', 'goal', 'court', 'marketing', 'program', 'suck', 'access', 'instagram', 'post', 'worst', 'cause', 'sock', 'actual', 'trash', 'hero', 'member', 'retail', 'sale', 'called', 'exclusive', 'manager', 'apple', 'future', 'child', 'shot', 'dress', 'step', 'dropping', 'fucking', 'glad', 'market', \"they're\", 'everything', 'original', 'crazy', 'bring', 'entire', 'knight', \"he's\", 'york', 'project', 'chicago', 'owner', 'royal', 'bet', 'idea', 'medium', 'fuck', 'nba', 'nfl', 'wnba', 'espn', 'netflix', 'amazon', 'cocacola', 'mcdonalds', 'nft', 'nfts', 'lazylionsnft', 'logo', 'tech', 'king', 'street', 'nov', 'design', 'dream', 'üôåüèΩ', 'wanted', 'second', 'left', 'law', 'wild', 'public', 'holy', 'impossible', 'lmao', 'wonder', 'grow', 'seeing', 'celebrating', 'christmas', 'green', 'pathetic', 'ball', 'seems', 'lost', 'listen', 'plane', 'triple', 'navy', 'nikestore', 'add', 'olympics', 'jordan', 'rest', 'box', 'player', 'slavery', 'lime', 'tonight', 'major', 'ban', 'air', \"can't\", 'final', 'solesavy', 'exec', 'retro', 'boot', 'nicekicks', 'ups', 'fuel', 'whole', 'cop', 'detail', 'ht', 'relationship', 'holiday', 'backpack', 'low', 'bro', 'walmart', 'corporate', 'america', 'example', 'red', 'meet', 'kit', 'brilliant', 'introducing', 'jersey', 'modern', 'content', 'playing', 'http', 'chinese', 'contract', 'image', 'sick', 'celtic', 'footlocker', 'neutral', 'latest', 'justintrudeau', 'summit', 'innovation', 'gotta', 'profit', 'soccer', 'stealing', 'several', 'bot', 'acquired', 'vp', 'blocked', 'deep', 'happened', 'sephora', 'uyghur', 'forced', 'david', 'son', 'digital', 'light', 'ice', 'dawn', 'newbalance', 'december', 'web', 'forum', 'labor', 'sneaker', 'üôèüèæ', 'nypdnews', 'prevention', 'alert', \"let's\", 'signed', 'steal', 'max', 'la', 'rule', 'em', 'college', 'usmc', 'young', 'mid', 'basketball', 'xinjiang', 'football', 'peo', 'tv', 'metaverse', 'dick', 'academy', 'midnight', 'shut', 'generation', 'november', 'kanyewest', 'festive', 'nikenyc', 'orange', 'charger', 'de', 'atmos_usa', 'sneakeradmirals', 'snkr_twitr', 'gatorade', 'ebay', 'adidasus', 'baseball', 'turtlepace5', 'adidasrunning', 'jack', 'recognizes', 'purple', 'exploring', 'thee']\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating helper function 'focus_edges' to clean up graph\n",
        "def focus_edges(G, brand_nodes = None, weight_min = None, weight_max = None):\n",
        "  # Filter based on a list of brand nodes to focus\n",
        "  if brand_nodes != None:\n",
        "    # Filter edges based on the weight threshold\n",
        "    filtered_edges = [(u, v) for u, v in G.edges() if u in brand_nodes or v in brand_nodes]\n",
        "    # Create a subgraph based on the filtered edges\n",
        "    G = G.edge_subgraph(filtered_edges)\n",
        "  # Filter based on weight threshold\n",
        "  if weight_min != None:\n",
        "    # Filter edges based on the weight threshold\n",
        "    filtered_edges = [(u, v) for u, v, d in G.edges(data=True) if d['weight'] >= weight_min]\n",
        "    # Create a subgraph based on the filtered edges\n",
        "    G = G.edge_subgraph(filtered_edges)\n",
        "  if weight_max != None:\n",
        "    # Filter edges based on the weight threshold\n",
        "    filtered_edges = [(u, v) for u, v, d in G.edges(data=True) if d['weight'] <= weight_max]\n",
        "    # Create a subgraph based on the filtered edges\n",
        "    G = G.edge_subgraph(filtered_edges)\n",
        "  # Return the filtered subgraph\n",
        "  return G"
      ],
      "metadata": {
        "id": "fzg2MvVbJtMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning up the semantic graph with 'focus_edges' function\n",
        "Semantic_Graph_cleaned = focus_edges(G = Semantic_Graph, weight_min = 10)"
      ],
      "metadata": {
        "id": "Su-RlvzRJifz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking number of nodes and edges in cleaned graph\n",
        "graph_summary_stats(G = Semantic_Graph_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y05yKoxbej7m",
        "outputId": "dffbbf9f-0340-4c65-c020-6f12a43b8db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "##### Graph Summary #####\n",
            "number of nodes: 911\n",
            "number of edges: 40032\n",
            "\n",
            "nodes: ['nike', \"women's\", 'air', 'uptempo', 'white', 'yellow', 'available', 'footlocker', 'sneakerscouts', 'adidas', 'lasership', 'stealing', 'work', 'home', 'alert', 'next', 'collab', 'dropping', 'ad', 'space', 'low', 'snipes_usa', 'snkrs', 'get', 'nikebasketball', 'puma', 'stock', 'partnership', 'helped', 'grow', 'etnow', 'team', 'release', 'jordan', 'real', 'support', 'friend', 'family', 'sick', 'kaya_alexander5', 'nikestore', 'sneakeradmirals', 'awesome', 'pair', 'lot', 'wait', 'dress', 'game', 'jumpman23', 'usnikefootball', 'usarmy', 'britisharmy', 'cnn', 'wheeloffortune', 'bloombergradio', 'wbpictures', 'disneystudios', 'wgci', 'hot97', 'v103', 'tmz', 'harveylevintmz', 'instagram', 'ebay', 'amazon', 'abc', 'abc7chicago', 'chicago_police', 'nypdnews', 'usairforce', 'usmc', 'usnavy', 'royalnavy', 'royalairforce', 'jack', 'finkd', 'priscillachanz', 'business', 'fbi', 'beccadiamondxx', 'potus', 'vp', 'drbiden44', 'bet', 'max', 'japan', 'ht', 'dunk', 'beautiful', 'fuck', 'working', 'sizeofficial', 'adidasus', 'adidasoriginals', 'look', 'problem', 'wearing', 'say', 'drop', 'time', 'vapormax', 'flyknit', 'royal', 'finishline', 'young', 'thetraeyoung', 'much', 'people', 'like', 'nicekicks', 'snkr_twitr', 'iamtmcii', 'good', 'edition', 'global', 'sport', 'week', 'take', 'place', 'black', 'lol', 'apple', 'think', 'corporation', 'care', 'latest', 'underarmour', 'deal', 'run', 'company', 'jersey', 'win', 'guy', 'see', 'way', 'keep', 'play', 'top', 'going', 'year', 'thank', 'great', 'getting', 'started', 'moment', 'connected', 'show', 'understand', \"they're\", 'making', 'tweet', 'want', 'others', 'word', 'kingjames', 'start', 'dude', 'blazer', 'suede', 'red', 'need', 'sneaker', 'day', 'color', 'style', 'code', 'date', 'price', 'sneakerhead', 'fashion', 'yes', 'know', 'free', 'used', 'celebrating', 'birthday', 'discount', 'item', 'thanks', 'given', 'something', 'trying', 'seen', 'issue', 'hand', 'let', 'make', 'sure', 'love', 'school', 'student', 'buy', 'quality', 'everyone', 'job', 'theestallion', 'thee', 'app', 'morning', 'history', 'step', 'go', 'shoe', 'part', 'facility', 'forum', 'mid', 'bot', 'sold', 'summit', 'bright', 'wolf', 'grey', 'hey', 'cool', 'pay', 'dropped', 'exclusive', 'access', 'long', 'member', 'got', 'account', 'brand', 'new', 'customer', 'bought', 'blue', 'month', 'light', 'cocacola', 'turn', 'join', 'please', 'city', 'lime', 'glow', 'kdtrey5', 'coach', 'sponsor', 'use', 'steal', 'package', 'delivery', 'put', 'left', 'le', 'minute', 'delivered', 'lululemon', 'bill', 'happy', 'friday', 'strong', 'weekend', 'jacket', 'deep', \"we're\", 'giving', 'store', 'head', 'wanted', 'hi', 'running', 'force', 'email', 'thing', \"i'm\", 'woman', 'god', 'service', 'idea', 'night', 'gonna', 'waiting', 'old', 'son', 'first', 'tv', 'espn', 'appreciate', 'wnba', 'help', 'change', 'move', 'kicksonfire', 'bro', 'best', 'custom', 'candace_parker', 'leader', 'human', 'right', 'order', 'congrats', 'manager', 'justdoit', 'pixel', 'se', 'gear', 'partner', 'wild', 'retail', 'http', 'second', 'season', 'yeah', 'bad', 'one', 'ice', 'soccer', 'ask', 'thought', 'kit', 'lfc', 'line', 'match', 'sock', 'york', 'looking', 'man', 'many', 'size', 'last', 'chance', 'said', 'wow', 'club', 'shop', 'shirt', 'law', 'tell', \"he's\", 'remember', 'decided', 'campaign', 'link', 'read', 'story', 'today', 'nikenyc', 'girl', 'point', 'smh', 'ni', 'continue', 'stay', 'boot', 'camp', 'swoosh', 'medium', 'em', 'hit', 'nice', 'add', 'tried', 'different', 'product', 'stop', 'adidasrunning', 'adidasfballus', 'adidashoops', 'htt', 'talking', 'shit', 'several', 'money', 'actual', 'virtual', 'event', 'fly', 'israel', 'glad', 'snkrfrkrmag', 'atmos_usa', 'theshoegame', 'üôèüèº', 'ticket', 'sale', 'la', 'tomorrow', 'gatorade', 'ordered', 'came', 'site', 'thesocialstatus', \"that's\", 'starting', 'dick', 'detail', 'yall', 'big', 'wtf', 'incredible', 'hippie', 'foot', 'fontanka', 'pink', 'find', 'kotd', 'yoursneakersaredope', 'kind', 'safe', 'exploring', 'lebron', 'james', 'college', 'wish', 'athlete', 'early', 'video', 'neutral', 'olive', 'travis', 'kick', 'fix', 'fan', 'wear', 'total', 'classic', 'green', 'selling', 'special', 'check', 'icon', 'able', 'follow', 'twitter', 'sb', 'box', 'football', 'believe', 'done', 'community', 'chicago', 'try', 'amazing', 'luck', 'life', 'short', 'holiday', 'face', 'talk', 'buying', 'pant', 'boy', 'pushed', 'send', 'ig', 'academy', 'woke', 'hoodie', 'favorite', 'orange', 'congratulation', 'feel', 'social', 'message', 'supply', 'crazy', 'tho', 'corporate', 'become', 'model', 'rest', 'world', 'pepsi', 'üôåüèΩ', 'online', 'paid', 'shipping', 'stuff', 'found', 'bring', 'back', 'christmas', 'uniform', 'report', 'high', 'forced', 'chinese', 'shut', 'guess', 'fire', 'watch', 'nikegolf', 'ball', 'nikefootball', 'pathetic', 'made', 'court', 'retro', 'modern', 'purchase', 'seeing', 'program', 'phil', 'knight', 'street', 'university', 'name', 'image', 'rule', 'official', 'clean', 'chicksinkicks2', 'shot', 'hour', 'soleguru', 'welcome', 'converse', 'slave', 'labor', 'clothing', \"can't\", 'number', 'gift', 'suck', 'biggest', 'person', 'innovation', 'fam', 'beiberlove69', 'stand', 'mean', 'wrong', 'type', 'question', 'original', 'come', 'wonder', 'speak', 'update', 'cause', 'website', 'triple', 'better', 'sell', 'im', 'purple', 'dawn', 'fedex', 'worst', 'fit', 'profit', 'called', 'consumersfirst', 'dm', 'took', 'design', 'example', 'kanyewest', 'cop', 'collection', 'content', 'super', 'dope', 'lost', 'ups', 'ship', 'walmart', 'refund', 'mind', 'logo', 'pack', 'heard', 'give', 'card', 'fun', 'true', 'mine', \"i've\", 'hope', 'meet', 'pick', 'gotta', 'dollar', 'american', 'fresh', 'state', 'boost', 'tech', 'side', 'griffey', 'future', 'controlled', 'return', 'netflix', 'present', 'nikeservice', 'saying', 'draw', 'passing', 'post', 'someone', 'lexxdaturtle', 'charger', 'thinking', 'commercial', 'vadriano2000', 'full', 'happen', 'damn', 'wanna', 'whole', 'anyone', 'baby', 'kid', 'hard', 'huge', 'perfect', 'hell', 'prize', 'taking', 'sorry', 'unlvfootball', 'uniswag', 'marketing', 'asking', 'nfl', 'chose', 'fact', 'nothing', 'raffle', 'leading', 'player', \"let's\", 'men', 'dear', 'clothes', 'missing', 'little', 'course', 'opening', 'ok', 'public', 'photo', 'end', 'child', 'hold', 'seems', 'sound', 'using', 'jamarrobrown', 'book', 'navy', 'nikesb', 'saw', 'loved', 'hear', 'ya', 'dream', 'as', 'nft', 'gold', 'collaboration', 'anything', 'sent', 'hate', 'playing', 'exec', 'call', 'reason', 'celebrate', 'newbalance', 'supporting', 'boston', 'least', 'share', 'mcdonalds', 'trash', 'went', 'yo', 'live', 'set', 'coming', 'solefed', 'apparel', 'anniversary', 'excited', 'midnight', 'china', 'employee', 'told', 'pic', 'jadendaly', 'target', 'fucking', 'worker', 'received', 'opportunity', 'boycott', 'tonight', 'listen', 'bit', 'matter', 'michael', 'trvisxx', 'nba', 'celtic', 'sign', 'country', 'meeting', 'proud', 'including', 'goal', 'canada', 'final', 'üôèüèæ', 'happened', 'lsoshipping', 'yesterday', 'agree', 'launch', 'basketball', 'ready', 'dirtydetty9381', 'nfts', 'phone', 'yeezy', 'list', 'impossibleisnothing', 'rock', 'speaking', 'donaldjtrumpjr', 'comment', 'maniere_usa', 'fast', 'kaepernick7', 'joshuajhan', 'xbox', 'december', 'bag', 'oh', 'dark', 'cosmic', 'unity', 'everything', 'solelinks', 'miss', 'introducing', 'experience', 'announced', 'act', 'foamposite', 'calling', '_talkswithtj', 'adizero', 'runningshoesgur', 'runningshoes', 'festive', 'signed', 'contract', 'fuel', 'credit', 'major', 'holy', 'inspire', 'reebok', 'teamcanada', 'impossible', 'slavery', 'inspired', 'open', 'project', 'olympics', 'create', 'spidadmitchell', 'respect', 'lmao', 'league', 'patta_nl', 'news', 'recent', 'america', 'jdsports', 'culture', 'enter', 'owner', 'market', 'eliudkipchoge', 'grail', 'boardroom', 'action', 'brilliant', 'blocked', 'djbluiz', 'changing', 'baseball', 'weareivypark', 'turtlepace5', 'shame', 'november', 'uno', 'region', 'deezle148', '210gotkickz', 'voice', 'on-court', 'repjimbanks', 'joebiden', 'billboard', 'digital', 'copping', 'xinjiang', 'david', 'xbox20', 'metaverse', 'analyst', 'entire', 'aaron', 'justintrudeau', 'relationship', 'king', 'de', 'dashiexp', 'yooo', 'imagine', 'import', 'banned', 'web', 'twotimesprime', 'uyghur', 'mindless_bmd', 'ayeeeee', 'postseason', 'statefarm', 'respond', 'ban', 'sneakerhd84', 'senator', 'centre', 'entering', 'beyonce', 'nov', 'backpack', 'solesavy', 'giannis_an34', 'twelve', 'thunder', 'hero', 'roblox', 'crater', 'donovan', 'mitchell', 'austinekeler', 'Ô∏ègiveaway', 'peo', 'michael_fabiano', 'slam', 'yardrunner', 'generation', 'easportsfifa', 'lied', 'heartbroken', 'acquired', 'duffel', 'taeyong', 'lazylionsnft', 'sephora', 'xboxsweepstakes', 'hyperkin', 'auxgod_', 'stern', 'bred', 'realunogame', 'plane', 'ingloriousguido', 'eneskanter', 'kanter', 'malcolmjackso20', 'recognizes', 'rtfktstudios', 'ene', 'meta', 'enduyghurforcedlabor', 'eth', 'uninterrupted', 'prevention', 'boredapeyc', 'garcons', 'brooklynsown90', 'graduation', 'scctradingcards', 'topps', 'virgil', 'lagalaxy', 'psg_english', 'elizabeth_that', 'rodgers', 'richsignorelli', 'techinsider', \"abloh's\", 'sen', 'nikeland', 'funneled', 'throne', 'nba_newyork', 'pre-day', 'enesfreedom', 'clonex', 'rtfkt', 'invsblefriends', 'footydotcom_', \"footy's\", 'zaptio', 'benitopagotto', 'spacerunnersnft', 'ronwyden', 'septe', 'maybes']\n",
            "\n",
            "neighbors of adidas: ['available', 'puma', 'stock', 'partnership', 'helped', 'grow', 'nike', 'real', 'get', 'support', 'friend', 'family', 'adidasus', 'adidasoriginals', 'look', 'problem', 'wearing', 'say', 'drop', 'young', 'thetraeyoung', 'much', 'people', 'like', 'lol', 'deal', 'black', 'run', 'company', 'thank', 'great', 'team', 'getting', 'started', 'dude', 'red', 'need', 'jersey', 'yes', 'start', 'know', 'free', 'used', 'history', 'step', 'play', 'forum', 'mid', 'bot', 'sold', 'bought', 'pair', 'blue', 'month', 'light', 'please', 'next', 'city', 'long', 'beautiful', 'sneaker', 'love', 'new', 'grey', 'year', 'wanted', 'thanks', 'service', 'shoe', 'keep', 'idea', 'night', 'gonna', 'human', 'right', 'brand', 'make', 'sure', 'gear', 'see', 'got', 'one', 'good', 'day', 'top', 'trying', 'tell', 'let', \"he's\", 'think', 'dropping', 'today', 'way', 'smh', 'snkr_twitr', 'adidasrunning', 'adidasfballus', 'adidashoops', \"we're\", 'glad', 'em', 'want', 'collab', 'tomorrow', 'man', 'show', 'site', 'wish', 'shop', 'underarmour', 'apple', 'awesome', 'first', 'athlete', 'size', 'fix', 'check', 'icon', 'able', 'believe', 'early', 'done', 'home', 'kit', 'follow', 'instagram', 'http', 'morning', 'try', 'amazing', 'luck', 'help', 'life', 'fan', 'buying', 'academy', 'shirt', 'woke', 'order', 'wait', 'online', 'fire', 'work', 'watch', 'boy', 'looking', 'fly', 'court', 'season', 'retro', 'time', 'store', 'purchase', 'official', 'face', 'win', 'guess', 'total', 'shot', 'tweet', 'hour', 'sale', 'price', 'clothing', 'question', 'original', 'program', 'point', 'world', 'better', 'hey', 'going', 'im', 'big', 'thought', 'dm', 'welcome', 'many', 'design', 'example', 'kanyewest', 'mind', 'ordered', 'mine', \"i've\", \"i'm\", 'old', 'head', 'hope', 'meet', 'pick', 'take', 'care', 'gotta', 'find', 'state', 'white', 'boost', 'tech', 'side', 'give', 'future', 'return', 'passing', 'post', 'thinking', 'commercial', 'guy', 'weekend', 'wanna', 'ask', 'girl', 'wild', 'card', 'prize', 'working', 'seen', 'fun', 'collection', \"that's\", 'nice', 'sell', 'college', 'move', 'several', 'style', 'feel', 'sock', 'dress', 'hoodie', \"women's\", 'pant', 'lasership', 'delivered', 'package', 'customer', 'saying', 'money', 'waiting', 'actual', 'cocacola', 'nft', 'favorite', 'sport', 'school', 'hard', 'bring', 'happy', 'birthday', 'last', 'newbalance', 'converse', 'supporting', 'boston', 'understand', 'sorry', 'everyone', 'put', 'dope', 'jacket', 'excited', 'share', 'coach', 'clean', \"let's\", 'buy', 'stop', 'video', 'something', 'thing', 'missing', 'made', 'green', 'player', 'tonight', 'super', 'high', 'talking', 'message', 'code', 'app', 'gold', 'collaboration', 'china', 'campaign', 'ad', 'asking', 'photo', 'ice', 'rule', 'sneakerhead', 'running', 'fit', 'whole', 'color', 'minute', 'saw', 'release', 'bro', 'walmart', 'target', 'set', 'le', 'football', 'short', 'taking', 'stay', 'ready', 'using', 'reason', 'seems', 'nfts', 'pay', 'join', 'kick', 'impossibleisnothing', 'employee', 'best', 'found', 'different', 'jumpman23', 'nfl', 'nba', 'bag', 'full', 'stand', 'said', 'corporation', \"can't\", 'wear', 'product', 'second', 'game', 'ups', 'paid', 'pack', 'phone', 'lost', 'hell', 'website', 'pic', 'send', 'retail', 'kid', 'fucking', 'sick', 'mean', 'perfect', 'happen', 'shipping', 'worst', 'shit', 'suck', 'speak', 'uniform', 'someone', 'crazy', 'announced', 'cool', 'live', 'street', 'classic', 'huge', 'cause', 'adizero', 'runningshoesgur', 'runningshoes', 'week', 'back', 'part', 'public', 'come', 'opportunity', 'god', 'kind', 'box', 'call', 'matter', 'line', 'bit', 'others', 'twitter', 'inspire', 'reebok', 'gatorade', 'kotd', 'yoursneakersaredope', 'safe', 'took', 'congrats', 'email', 'use', 'lot', 'discount', 'go', 'bad', 'celebrate', 'change', 'impossible', 'nothing', 'remember', 'name', 'anything', 'match', 'orange', 'member', 'experience', 'exclusive', 'went', 'goal', 'congratulation', 'turn', 'amazon', 'proud', 'add', 'number', 'damn', 'true', 'basketball', 'giving', 'sponsor', 'clothes', 'soccer', 'link', 'ok', 'course', 'open', 'nikebasketball', 'woman', 'enter', 'corporate', 'global', 'fedex', 'happened', 'delivery', 'yeezy', 'steal', 'stuff', 'hand', 'refund', 'wtf', 'nikestore', 'owner', 'date', 'detail', 'ig', 'social', 'medium', 'low', 'quality', 'apparel', 'blocked', 'edition', 'making', 'hi', 'marketing', 'business', 'mcdonalds', 'selling', 'foot', 'virtual', 'seeing', 'yo', 'üôåüèΩ', 'lmao', 'called', 'content', 'dream', 'pink', 'rock', 'everything', 'comment', 'ball', 'november', 'footlocker', 'story', 'partner', 'gift', 'son', 'xbox', 'tho', 'news', 'alert', 'pepsi', 'market', 'recent', 'country', 'tried', 'trash', 'read', 'community', 'club', 'book', 'holiday', 'type', 'little', 'become', 'account', 'as', 'innovation', 'boot', 'üôèüèº', 'special', 'report', 'sneakeradmirals', 'end', 'sound', 'chose', '_talkswithtj', 'told', 'respect', 'item', 'issue', 'came', 'anyone', 'james', 'vp', 'fuck', 'xbox20', 'anniversary', 'ebay', \"they're\", 'celebrating', 'coming', 'cop', 'inspired', 'launch', 'wrong', 'list', 'aaron', 'wow', 'fresh', 'la', 'king', 'ticket', 'signed', 'nicekicks', 'iamtmcii', 'beiberlove69', 'including', 'fact', 'word', 'air', 'event', 'dashiexp', 'yooo', 'sent', 'culture', 'baby', 'yall', 'logo', 'yeah', 'jack', 'fam', 'candace_parker', 'least', 'model', 'hold', 'holy', 'credit', 'america', 'left', 'jordan', 'force', 'american', 'changing', 'fashion', 'wnba', 'michael', 'latest', 'hit', 'job', 'sizeofficial', 'received', 'men', 'slave', 'labor', 'wonder', 'miss', 'person', 'appreciate', 'dropped', 'dear', 'netflix', 'navy', 'espn', 'royal', 'draw', 'space', 'ship', 'chance', 'child', 'place', 'given', 'worker', 'playing', 'starting', 'weareivypark', 'beyonce', 'supply', 'sign', 'entering', 'bet', 'oh', 'introducing', 'heard', 'contract', 'baseball', 'dick', 'update', 'yesterday', 'nov', 'continue', 'decided', 'solelinks', 'league', 'moment', 'talk', 'final', 'stealing', 'major', 'statefarm', 'christmas', 'student', 'fast', 'snkrs', 'image', 'digital', 'dark', 'hate', 'create', 'rest', 'dunk', 'chicago', 'triple', 'spidadmitchell', 'dollar', 'relationship', 'ya', 'pathetic', 'leader', 'hear', 'raffle', 'access', 'agree', 'university', 'action', 'donovan', 'mitchell', 'friday', 'austinekeler', 'Ô∏ègiveaway', 'respond', 'peo', 'charger', 'michael_fabiano', 'shut', 'atmos_usa', 'leading', 'chinese', 'kicksonfire', 'strong', 'üôèüèæ', 'solefed', 'imagine', 'incredible', 'generation', 'easportsfifa', 'kingjames', 'entire', 'biggest', 'custom', 'present', 'opening', 'project', 'taeyong', 'hero', 'xboxsweepstakes', 'hyperkin', 'act', 'travis', 'roblox', 'bright', 'turtlepace5', 'grail', 'boycott', 'shame', 'loved', 'lexxdaturtle', 'deezle148', 'finishline', 'ht', 'slam', 'jdsports', 'manager', 'htt', 'eneskanter', 'nikesb', 'nikeservice', 'giannis_an34', 'solesavy', 'sephora', 'lfc', 'lagalaxy', 'topps', 'profit', 'listen', 'boredapeyc', 'york', 'pixel', 'december', 'fbi', 'rodgers', 'yellow', 'meta', 'richsignorelli', 'lied', 'analyst', 'web', 'metaverse', 'eth', 'rtfktstudios', 'kaya_alexander5', 'facility', 'jadendaly', 'abc', 'senator', 'potus', 'olive', 'lazylionsnft', 'de', 'boardroom', 'snkrfrkrmag', 'rtfkt', 'maybes']\n",
            "neighbors of nike: [\"women's\", 'air', 'uptempo', 'white', 'yellow', 'available', 'footlocker', 'sneakerscouts', 'lasership', 'stealing', 'work', 'home', 'alert', 'next', 'collab', 'dropping', 'snkrs', 'get', 'nikebasketball', 'puma', 'stock', 'partnership', 'helped', 'grow', 'adidas', 'etnow', 'team', 'release', 'jordan', 'sick', 'lot', 'wait', 'dress', 'usarmy', 'britisharmy', 'cnn', 'wheeloffortune', 'bloombergradio', 'wbpictures', 'disneystudios', 'wgci', 'hot97', 'v103', 'tmz', 'harveylevintmz', 'instagram', 'ebay', 'amazon', 'abc', 'abc7chicago', 'chicago_police', 'nypdnews', 'usairforce', 'usmc', 'usnavy', 'royalnavy', 'royalairforce', 'jack', 'finkd', 'priscillachanz', 'business', 'fbi', 'beccadiamondxx', 'potus', 'vp', 'drbiden44', 'bet', 'ad', 'max', 'japan', 'snipes_usa', 'ht', 'dunk', 'beautiful', 'sizeofficial', 'time', 'vapormax', 'flyknit', 'royal', 'finishline', 'jumpman23', 'sneakeradmirals', 'nicekicks', 'snkr_twitr', 'iamtmcii', 'look', 'good', 'black', 'apple', 'think', 'people', 'corporation', 'care', 'latest', 'underarmour', 'working', 'win', 'guy', 'see', 'way', 'keep', 'play', 'say', 'top', 'going', 'year', 'moment', 'connected', 'show', 'understand', \"they're\", 'making', 'tweet', 'want', 'others', 'space', 'low', 'kingjames', 'edition', 'start', 'blazer', 'suede', 'getting', 'celebrating', 'birthday', 'discount', 'item', 'thanks', 'given', 'something', 'trying', 'seen', 'issue', 'hand', 'go', 'shoe', 'part', 'facility', 'support', 'summit', 'bright', 'wolf', 'grey', 'cocacola', 'turn', 'join', 'problem', 'lime', 'glow', 'kdtrey5', 'new', 'coach', 'sponsor', 'use', 'company', 'steal', 'package', 'delivery', 'put', 'left', 'le', 'minute', 'delivered', 'week', 'deep', 'know', 'thing', \"i'm\", 'woman', 'day', 'god', 'waiting', 'red', 'let', 'order', 'congrats', 'customer', 'manager', 'justdoit', 'force', 'pixel', 'se', 'happy', 'partner', 'wild', 'retail', 'http', 'second', 'season', 'yeah', 'bad', 'lol', 'ice', 'soccer', 'store', 'ask', 'thought', 'kit', 'lfc', 'real', 'line', 'match', 'sock', 'york', 'game', 'custom', 'jersey', 'man', 'many', 'pair', 'size', 'last', 'chance', 'said', 'sold', 'wow', 'club', 'shop', 'shirt', 'please', 'remember', 'app', 'nikenyc', 'girl', 'point', 'blue', 'night', 'ni', 'love', 'swoosh', 'htt', 'today', 'several', 'job', 'make', 'money', 'actual', 'virtual', 'event', 'take', 'link', 'israel', 'right', 'snkrfrkrmag', 'atmos_usa', 'theshoegame', 'üôèüèº', 'great', 'nikestore', 'gatorade', 'dick', 'sure', 'detail', 'incredible', 'global', 'brand', 'hippie', 'light', 'fontanka', 'pink', 'need', 'medium', 'city', 'exploring', 'neutral', 'olive', 'stop', 'giving', 'travis', 'kick', 'buy', 'total', 'classic', 'green', 'college', 'started', 'sport', 'story', 'check', 'sb', 'box', 'sneaker', 'thank', 'pant', 'boy', 'got', 'pushed', 'send', 'hoodie', 'favorite', 'color', 'orange', 'product', 'corporate', 'become', 'model', 'rest', 'world', 'pepsi', 'üôåüèΩ', 'shipping', 'found', 'bring', 'back', 'christmas', 'uniform', 'report', 'high', 'price', 'forced', 'chinese', 'shut', 'woke', 'best', 'nikegolf', 'ball', 'nikefootball', 'pathetic', 'made', 'big', 'able', 'seeing', 'program', 'purchase', 'school', 'luck', 'phil', 'knight', 'street', 'university', 'athlete', 'name', 'image', 'rule', 'chicksinkicks2', 'much', 'kaya_alexander5', 'soleguru', 'welcome', 'converse', 'holiday', 'slave', 'labor', \"can't\", 'number', 'gift', 'suck', 'innovation', 'fam', 'beiberlove69', 'quality', 'stand', 'mean', 'wrong', 'wish', 'type', 'come', 'em', 'wonder', 'cause', 'website', 'selling', 'lebron', 'triple', 'sell', 'run', 'purple', 'dawn', 'fan', 'fedex', 'worst', 'help', 'foot', 'fit', 'profit', 'called', 'cop', 'believe', 'collection', 'content', 'super', 'dope', 'bro', 'lost', 'ups', 'service', 'ship', 'walmart', 'refund', 'awesome', 'logo', 'pack', 'fun', 'true', 'watch', 'looking', 'give', 'fuck', 'dollar', 'american', 'buying', 'shit', 'fresh', 'griffey', 'tell', 'netflix', 'campaign', 'present', 'add', 'draw', 'lexxdaturtle', 'gonna', 'charger', 'vadriano2000', 'full', 'community', 'one', 'ordered', 'happen', 'ig', 'nice', 'damn', 'paid', 'whole', 'appreciate', 'free', 'anyone', 'word', 'strong', 'baby', 'amazing', 'hell', 'mine', 'weekend', 'tried', 'unlvfootball', 'usnikefootball', 'uniswag', 'hi', 'marketing', 'month', 'done', 'theestallion', 'raffle', 'long', 'player', 'im', 'clothes', 'nothing', 'missing', 'speak', 'retro', 'little', 'fashion', 'sale', 'online', 'photo', 'follow', 'end', 'child', 'question', 'gear', 'nfl', 'first', 'place', 'seems', 'fire', 'icon', 'yes', 'nikeservice', 'book', 'navy', 'cool', 'nikesb', 'saw', 'loved', 'old', 'bought', 'talk', 'social', 'glad', 'pay', 'hard', 'try', 'fix', 'gold', 'wearing', 'anything', 'sent', 'hate', 'playing', 'call', 'yall', 'gotta', 'video', 'feel', 'deal', \"that's\", 'newbalance', 'took', 'hit', 'least', \"we're\", 'life', 'share', 'design', 'hey', 'mcdonalds', 'trash', 'dude', 'wear', 'went', 'yo', 'face', 'person', 'used', 'talking', 'better', 'reason', 'stuff', 'friday', 'set', 'coming', 'solefed', 'kicksonfire', 'son', 'apparel', 'anniversary', 'kid', 'excited', 'change', 'live', 'midnight', 'everyone', 'yoursneakersaredope', 'kotd', 'tomorrow', 'head', 'wanted', 'china', 'employee', 'told', 'crazy', 'came', 'shot', 'dream', 'clean', 'jamarrobrown', 'jadendaly', 'target', 'bill', 'fucking', 'find', 'style', 'opportunity', 'boycott', 'tv', 'commercial', 'running', 'state', 'fact', 'modern', 'football', 'listen', 'saying', 'michael', 'trvisxx', 'nba', 'celtic', 'including', 'meet', 'goal', 'sneakerhead', 'canada', 'someone', 'worker', 'move', 'young', 'final', 'opening', 'üôèüèæ', 'dropped', 'country', 'hope', 'site', 'men', 'agree', 'original', 'future', 'jacket', 'different', 'launch', 'exclusive', 'sign', 'course', 'basketball', 'academy', 'family', 'bot', 'taking', 'dirtydetty9381', 'ok', 'post', 'sorry', 'as', 'phone', 'member', 'thinking', 'guess', 'list', 'using', 'hour', 'supporting', 'drop', 'yesterday', 'donaldjtrumpjr', 'comment', 'maniere_usa', 'chicago', 'fast', 'kaepernick7', 'morning', 'ready', 'idea', 'joshuajhan', 'xbox', 'tho', 'adidasus', 'perfect', 'hear', 'december', 'kind', 'example', 'return', 'huge', 'dear', 'dark', 'wanna', 'asking', 'friend', 'cosmic', 'unity', 'official', 'miss', 'stay', 'special', 'dm', 'introducing', 'experience', 'thee', 'decided', 'short', 'access', 'everything', 'act', \"i've\", 'foamposite', 'date', 'calling', '_talkswithtj', 'like', 'festive', 'continue', 'read', 'fuel', 'credit', 'oh', 'hold', 'major', 'card', 'message', 'congratulation', 'twitter', 'holy', 'inspire', 'reebok', 'james', 'boston', 'student', 'email', 'espn', 'safe', 'biggest', 'nfts', \"he's\", 'camp', 'prize', 'la', 'inspired', \"let's\", 'wnba', 'open', 'court', 'project', 'olympics', 'pick', 'contract', 'leading', 'clothing', 'league', 'patta_nl', 'news', 'ya', 'early', 'meeting', 'boot', 'step', 'america', 'jdsports', 'culture', 'mid', 'side', 'create', 'announced', 'owner', 'market', 'wtf', 'eliudkipchoge', 'grail', 'received', 'solelinks', 'pic', 'tech', 'collaboration', 'brilliant', 'respect', 'adidasoriginals', 'update', 'djbluiz', 'changing', 'smh', 'baseball', 'bit', 'turtlepace5', 'account', 'celebrate', 'sound', 'mind', 'shame', 'bag', 'november', 'matter', 'region', 'happened', 'nft', 'uno', 'starting', 'blocked', 'recent', 'lmao', 'heard', 'signed', 'voice', 'on-court', 'repjimbanks', 'supply', 'joebiden', 'proud', 'billboard', 'lsoshipping', 'rock', 'boardroom', '210gotkickz', 'xinjiang', 'david', 'fly', 'controlled', 'history', 'lululemon', 'law', 'enter', 'deezle148', 'justintrudeau', 'digital', 'relationship', 'de', 'action', 'import', 'human', 'web', 'banned', 'twotimesprime', 'king', 'entire', 'tonight', 'kanyewest', 'uyghur', 'mindless_bmd', 'ayeeeee', 'boost', 'respond', 'copping', 'imagine', 'passing', 'consumersfirst', 'thesocialstatus', 'code', 'slavery', 'senator', 'entering', 'speaking', 'public', 'sneakerhd84', 'impossible', 'leader', 'backpack', 'candace_parker', 'solesavy', 'exec', 'giannis_an34', 'twelve', 'ticket', 'hero', 'metaverse', 'roblox', 'yeezy', 'crater', 'adidashoops', 'slam', 'yardrunner', 'aaron', 'lied', 'heartbroken', 'nov', 'acquired', 'ban', 'postseason', 'lazylionsnft', 'chose', 'centre', 'sephora', 'auxgod_', 'realunogame', 'eneskanter', 'kanter', 'taeyong', 'recognizes', 'malcolmjackso20', 'bred', 'rtfktstudios', 'ene', 'thunder', 'plane', 'enduyghurforcedlabor', 'uninterrupted', 'forum', 'prevention', 'boredapeyc', 'generation', 'brooklynsown90', 'garcons', 'scctradingcards', 'topps', 'duffel', 'virgil', 'meta', 'psg_english', 'ingloriousguido', 'elizabeth_that', 'eth', 'graduation', 'statefarm', 'rodgers', 'richsignorelli', 'techinsider', \"abloh's\", 'beyonce', 'nikeland', 'nba_newyork', 'sen', 'pre-day', 'enesfreedom', 'throne', 'rtfkt', 'invsblefriends', 'footydotcom_', \"footy's\", 'zaptio', 'clonex', 'benitopagotto', 'spacerunnersnft', 'ronwyden', 'funneled', 'septe']\n",
            "neighbors of lululemon: ['thank', 'bill', 'happy', 'friday', 'let', 'week', 'strong', 'great', 'weekend', 'jacket', 'nice', 'running', 'thanks', 'early', 'video', 'job', 'top', 'beautiful', 'follow', 'twitter', 'congratulation', 'feel', 'please', 'make', 'supply', 'brand', 'fashion', 'hey', 'order', 'paid', 'shipping', 'seen', 'stuff', 'life', 'new', 'person', 'event', 'got', 'good', 'friend', 'put', 'everyone', 'kind', 'took', 'long', 'old', 'school', 'appreciate', 'love', 'awesome', 'need', 'give', 'place', 'card', 'buy', 'day', 'read', 'try', 'wish', 'store', 'get', 'ask', 'know', 'best', 'thing', 'ordered', 'question', 'customer', 'service', 'said', 'run', 'size', 'huge', 'return', 'pair', 'perfect', 'fit', 'one', 'find', 'something', 'super', 'club', 'sponsor', 'product', 'way', 'keep', 'lol', 'hold', 'wearing', 'mind', 'business', 'see', 'stay', 'collection', 'made', 'sound', 'uniform', 'time', 'season', \"i'm\", 'guy', 'think', 'hear', \"i've\", 'god', 'shop', 'chance', 'im', 'pack', 'favorite', 'underarmour', 'deal', 'shirt', 'space', 'pant', 'look', 'discount', 'worker', 'show', 'anyone', 'received', 'package', 'say', 'delivered', 'help', 'yeah', 'sign', 'given', 'kid', 'country', 'tell', 'mean', 'smh', 'set', 'hell', 'many', 'employee', 'short', 'fix', 'home', 'work', 'take', 'shoe', 'coming', 'thought', 'hate', 'come', 'gear', 'hit', 'people', 'man', 'speak', 'team', 'wow', 'site', 'last', 'night', 'oh', 'going', 'right', 'fan', 'told', 'money', 'wrong', 'line', 'point', 'real', 'better', 'website', 'lot', 'year', 'abc', 'want', 'stop', 'join', 'community', 'tweet', 'hoodie', 'style', 'miss', 'saw', 'getting', 'morning', 'hope', 'talk', 'family', 'global', 'free', 'send', 'clothes', 'go', 'tomorrow', 'call', 'move', 'teamcanada', 'amazing', 'fam', 'share', 'world', 'today', 'high', 'bag', 'check', \"we're\", 'hour', 'experience', 'working', 'fire', 'others', 'change', 'present', 'moment', 'like', 'purchase', 'item', 'full', 'refund', 'le', 'minute', 'reason', 'woman', 'create', 'list', 'respect', 'wear', 'company', 'fact', 'first', 'clothing', 'wait', 'bit', 'gift', 'ship', 'next', 'excited', 'part', 'using', 'found', 'including', 'sell', 'sold', 'sent', 'nothing', 'anything', 'gonna', 'special', 'use', 'official', 'code', 'opportunity', 'different', 'news', 'action', 'mine', 'calling', 'name', 'comment', 'fast', 'hard', 'start', 'ok', 'online', 'waiting', 'someone', 'phone', 'trying', 'support', 'message', 'came', 'done', 'decided', 'email', 'went', 'end', 'human', 'price', 'sure', 'saying', 'china', 'bought', 'game', 'white', 'black', 'ready', 'word', 'clean', 'partnership', 'apparel', 'much', 'birthday', 'turn', 'heard', 'target', 'yesterday', 'credit', 'partner', 'color', 'cool', 'social', 'changing', 'missing', 'guess', 'starting', 'believe', 'type', 'opening', 'virtual', 'fun', 'helped', 'live', 'started', 'jumpman23', 'girl', 'ad', 'account', 'looking', 'nike', 'taking', 'number', 'damn', 'yo', 'model', \"that's\", 'canada', 'athlete', 'imagine', 'thinking', 'care', 'shame', 'report', 'buying', 'little', 'able', 'supporting', 'back', 'big', 'shit', 'open', 'puma', 'sport', 'proud', 'update', 'dropped', 'dollar', 'fedex', 'stand', 'luck', 'hi', 'continue', 'welcome', 'month', 'head', 'act', 'available', 'asking', 'pay', 'happen', 'launch', 'agree', 'making', 'photo', 'story', 'used', 'matter', 'giving', 'sorry', 'issue', 'coach', 'bad', 'link', 'side', 'state', 'as', 'quality', 'dear', 'least', 'true', 'city', 'understand', 'hand', 'stock', 'book', 'pick', 'fresh', 'face', 'incredible', 'dude', 'men', 'tried', 'respond', 'pic', 'drop', 'problem', 'yes', 'delivery', 'win', 'congrats', 'loved', 'watch', 'wtf', 'talking', 'dm', 'goal', 'marketing', 'program', 'post', 'worst', 'cause', 'hero', 'member', 'retail', 'sale', 'called', 'apple', 'future', 'dress', 'step', 'dropping', 'fucking', 'market', \"they're\", 'everything', 'crazy', 'bring', 'entire', 'york', 'project', 'bet', 'idea', 'nba', 'nfl', 'wnba', 'espn', 'netflix', 'amazon', 'mcdonalds', 'nft', 'logo', 'tech', 'street', 'design', 'wanted', 'second', 'left', 'public', 'grow', 'seeing', 'christmas', 'ball', 'seems', 'lost', 'plane', 'add', 'olympics', 'rest', 'tonight', \"can't\", 'final', 'whole', 'holiday', 'low', 'bro', 'walmart', 'red', 'meet', 'kit', 'gotta', 'happened', 'academy', 'generation']\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating Subgraphs**"
      ],
      "metadata": {
        "id": "GS615exDfKjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and defining node interactions and connections\n",
        "# Kudos to 'Chiuchiyin'! The following code chunk has been adapted from their work\n",
        "\n",
        "# Defining key nodes\n",
        "key_nodes_all = ['nike', 'lululemon', 'adidas']\n",
        "key_nodes_nl = ['nike', 'lululemon']\n",
        "key_nodes_na = ['nike', 'adidas']\n",
        "key_nodes_al = ['adidas', 'lululemon']\n",
        "\n",
        "# Finding neighbors of the key nodes by themselves\n",
        "neighbors_sets_n = set(nx.all_neighbors(Semantic_Graph_cleaned, 'nike'))\n",
        "neighbors_sets_a = set(nx.all_neighbors(Semantic_Graph_cleaned, 'adidas'))\n",
        "neighbors_sets_l = set(nx.all_neighbors(Semantic_Graph_cleaned, 'lululemon'))\n",
        "\n",
        "# Finding neighbors of the key nodes\n",
        "neighbors_sets_all = [set(nx.all_neighbors(Semantic_Graph_cleaned, node)) for node in key_nodes_all]\n",
        "neighbors_sets_nl = [set(nx.all_neighbors(Semantic_Graph_cleaned, node)) for node in key_nodes_nl]\n",
        "neighbors_sets_na = [set(nx.all_neighbors(Semantic_Graph_cleaned, node)) for node in key_nodes_na]\n",
        "neighbors_sets_al = [set(nx.all_neighbors(Semantic_Graph_cleaned, node)) for node in key_nodes_al]\n",
        "\n",
        "# Intersecting the sets to get nodes connected to all key nodes\n",
        "common_neighbors_all = set.intersection(*neighbors_sets_all)\n",
        "\n",
        "# Intersecting the sets to get nodes connected to only 2 key nodes\n",
        "common_neighbors_nl = set.intersection(*neighbors_sets_nl) - common_neighbors_all - set(key_nodes_al)\n",
        "common_neighbors_na = set.intersection(*neighbors_sets_na) - common_neighbors_all - set(key_nodes_nl)\n",
        "common_neighbors_al = set.intersection(*neighbors_sets_al) - common_neighbors_all - set(key_nodes_na)\n",
        "\n",
        "# Getting nodes connected to any one of the key nodes but not all of them\n",
        "union_neighbors = set.union(*neighbors_sets_all)\n",
        "\n",
        "# Getting nodes connected to only 1 brand\n",
        "exclusive_neighbors = (union_neighbors - common_neighbors_all\n",
        "                       - common_neighbors_nl - common_neighbors_na - common_neighbors_al)\n",
        "\n",
        "# Getting nodes connected to each specific brand\n",
        "exclusive_neighbors_n = neighbors_sets_n - common_neighbors_all - common_neighbors_nl - common_neighbors_na - set(key_nodes_al)\n",
        "exclusive_neighbors_a = neighbors_sets_a - common_neighbors_all - common_neighbors_na - common_neighbors_nl - set(key_nodes_nl)\n",
        "exclusive_neighbors_l = neighbors_sets_l - common_neighbors_all - common_neighbors_nl - common_neighbors_al - set(key_nodes_na)"
      ],
      "metadata": {
        "id": "tlpoAJV2eIMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating subgraphs\n",
        "\n",
        "# Creating subgraph of bridges between all brand nodes\n",
        "nodes_to_keep_all = list(common_neighbors_all) + key_nodes_all\n",
        "Semantic_Graph_bridge_all = focus_edges(Semantic_Graph_cleaned, weight_min=125).subgraph(nodes_to_keep_all)\n",
        "\n",
        "# Creating subgraph of bridges between Nike & Adidas\n",
        "nodes_to_keep_na = list(common_neighbors_na) + key_nodes_na\n",
        "Semantic_Graph_bridge_na = Semantic_Graph_cleaned.subgraph(nodes_to_keep_na)\n",
        "\n",
        "# Creating subgraph of bridges between Nike & Lululemon\n",
        "nodes_to_keep_nl = list(common_neighbors_nl) + key_nodes_nl\n",
        "Semantic_Graph_bridge_nl = Semantic_Graph_cleaned.subgraph(nodes_to_keep_nl)\n",
        "\n",
        "# Creating subgraph of bridges between Adidas & Lululemon\n",
        "nodes_to_keep_al = list(common_neighbors_al) + key_nodes_al\n",
        "Semantic_Graph_bridge_al = Semantic_Graph_cleaned.subgraph(nodes_to_keep_al)"
      ],
      "metadata": {
        "id": "HzzD9M0Df46f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the summaries of the new subgraphs\n",
        "graph_summary_stats(G = Semantic_Graph_bridge_all, title='Bridges Between All Brand Nodes')\n",
        "graph_summary_stats(G = Semantic_Graph_bridge_na, title='Nike & Adidas Bridges')\n",
        "graph_summary_stats(G = Semantic_Graph_bridge_nl, title='Nike & Lululemon Bridges')\n",
        "graph_summary_stats(G = Semantic_Graph_bridge_al, title='Adidas & Lululemon Bridges')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5sAHnYKgKuQ",
        "outputId": "0369fe6e-cced-4796-eb3e-a7c5dd6f9ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "##### Bridges Between All Brand Nodes #####\n",
            "number of nodes: 453\n",
            "number of edges: 1220\n",
            "\n",
            "nodes: ['minute', 'love', 'stand', 'guy', 'find', 'fashion', 'change', 'seeing', 'month', 'money', 'delivered', 'let', 'long', 'found', 'something', 'opportunity', 'underarmour', 'dollar', 'taking', 'decided', 'lost', 'online', 'yo', 'program', 'list', 'puma', 'le', 'public', 'hell', 'beautiful', 'congrats', 'pic', 'book', 'type', 'news', 'gonna', 'clothes', 'new', 'incredible', 'move', 'smh', 'person', 'end', 'get', 'thank', 'collection', 'pick', 'loved', 'others', 'opening', 'right', 'awesome', 'running', 'wtf', 'real', 'delivery', 'missing', 'work', 'used', 'early', 'tried', 'wrong', 'shit', 'twitter', 'buying', 'people', 'sold', 'logo', 'experience', 'red', 'last', 'like', 'lot', 'today', 'ok', 'sale', 'service', 'fit', 'respond', 'rest', 'low', 'fan', 'stuff', 'clean', 'cause', 'gift', 'discount', 'jumpman23', 'wnba', 'state', 'pack', 'member', \"we're\", 'check', 'marketing', 'making', 'damn', 'fun', 'talking', 'future', 'point', 'first', 'cool', 'generation', 'kind', 'called', 'hey', 'life', 'congratulation', 'least', 'bet', 'nft', 'whole', 'next', 'head', 'welcome', 'entire', 'better', 'help', 'continue', 'put', 'big', 'everything', 'partnership', 'community', 'high', 'friend', 'tech', 'different', 'retail', 'fedex', 'espn', 'available', 'friday', \"i'm\", 'create', 'send', 'ready', 'social', 'school', 'back', 'business', 'fact', 'black', 'christmas', 'everyone', 'crazy', 'luck', 'stock', 'took', 'care', 'gear', 'account', 'coming', 'got', 'many', 'asking', 'much', 'man', 'call', 'part', 'credit', 'club', 'present', 'respect', 'message', 'thinking', 'final', 'birthday', 'fix', 'grow', 'sure', 'someone', 'proud', 'hoodie', 'email', 'woman', 'shipping', 'market', 'feel', 'target', 'believe', 'anyone', 'as', 'launch', 'nice', 'street', 'item', 'coach', 'yeah', 'say', 'white', 'wow', 'excited', 'please', 'hold', 'guess', 'side', 'holiday', 'watch', 'pant', 'follow', 'understand', 'family', 'brand', \"i've\", 'think', 'supporting', 'price', 'drop', 'stay', 'give', 'agree', 'goal', 'fire', 'see', 'turn', 'god', 'space', 'sound', 'amazing', 'perfect', 'happy', 'hand', 'take', 'full', 'netflix', 'global', 'nba', 'one', \"that's\", 'post', 'athlete', 'apparel', 'city', 'york', 'hero', 'ad', 'hate', 'wanted', 'happen', 'hour', 'look', 'top', 'buy', 'sent', 'nfl', 'little', 'imagine', 'free', 'year', 'using', 'refund', 'men', 'apple', 'try', 'human', 'pay', 'win', 'pair', 'add', 'given', 'able', 'academy', 'order', 'open', 'video', 'old', 'tell', 'left', 'read', 'mine', 'started', 'world', 'hit', 'fam', 'matter', 'hear', 'said', 'return', 'oh', 'sport', 'nike', 'fresh', 'idea', 'code', 'game', 'moment', 'speak', 'ask', 'mind', 'giving', 'partner', 'received', 'time', 'country', 'bro', 'design', 'reason', 'line', 'set', 'chance', 'favorite', 'run', \"can't\", 'company', 'place', 'way', 'ship', 'sell', 'shame', 'thanks', 'make', 'project', 'talk', 'getting', 'number', 'tweet', 'ordered', 'question', 'team', 'kit', 'thought', 'show', 'wear', 'saying', \"they're\", 'come', 'start', 'site', 'night', 'dress', 'walmart', 'dude', 'story', 'girl', 'tomorrow', 'appreciate', 'yesterday', 'worst', 'quality', 'morning', 'im', 'amazon', 'need', 'miss', 'sorry', 'live', 'lululemon', 'package', 'shoe', 'purchase', 'join', 'photo', 'meet', 'yes', 'adidas', 'seems', 'strong', 'waiting', 'paid', 'saw', 'good', 'home', 'anything', 'wish', 'virtual', 'hope', 'china', 'job', 'short', 'special', 'style', 'support', 'deal', 'want', 'card', 'going', 'phone', 'huge', 'dropped', 'sponsor', 'official', 'happened', 'thing', 'done', 'day', 'told', 'uniform', 'worker', 'product', 'season', 'name', 'report', 'abc', 'model', 'working', 'go', 'mean', 'share', 'fast', 'clothing', 'super', 'best', 'made', 'ball', 'face', 'including', 'lol', 'website', 'keep', 'bad', 'great', 'supply', 'second', 'helped', 'stop', 'act', 'nothing', 'shop', 'tonight', 'size', 'sign', 'fucking', 'link', 'bought', 'true', 'seen', 'employee', 'trying', 'color', 'week', 'wearing', 'bring', 'word', 'wait', 'update', 'dm', 'shirt', 'problem', 'issue', 'customer', 'use', 'came', 'dear', 'know', 'mcdonalds', 'went', 'kid', 'store', 'gotta', 'hard', 'looking']\n",
            "\n",
            "neighbors of adidas: ['available', 'puma', 'partnership', 'nike', 'real', 'get', 'support', 'friend', 'family', 'look', 'wearing', 'say', 'drop', 'much', 'people', 'lol', 'deal', 'black', 'run', 'company', 'thank', 'great', 'team', 'getting', 'need', 'start', 'know', 'free', 'pair', 'month', 'please', 'next', 'long', 'love', 'new', 'year', 'thanks', 'service', 'shoe', 'keep', 'gonna', 'right', 'brand', 'make', 'sure', 'gear', 'see', 'got', 'one', 'good', 'day', 'top', 'trying', 'let', 'think', 'today', 'way', 'want', 'man', 'show', 'underarmour', 'awesome', 'first', 'size', 'check', 'kit', 'follow', 'amazing', 'help', 'life', 'fan', 'shirt', 'order', 'wait', 'online', 'work', 'looking', 'season', 'time', 'store', 'purchase', 'win', 'program', 'point', 'world', 'better', 'hey', 'going', 'big', 'many', 'design', \"i'm\", 'hope', 'take', 'find', 'white', 'tech', 'give', 'thinking', 'guy', 'card', 'collection', 'nice', 'style', 'hoodie', 'package', 'customer', 'money', 'nft', 'sport', 'happy', 'last', 'everyone', 'put', 'excited', 'coach', 'buy', 'stop', 'something', 'thing', 'made', 'ad', 'running', 'saw', 'walmart', 'stay', 'best', 'jumpman23', 'nfl', 'nba', \"can't\", 'wear', 'product', 'game', 'website', 'send', 'shit', 'crazy', 'cool', 'week', 'come', 'call', 'twitter', 'congrats', 'use', 'go', 'nothing', 'anything', 'went', 'amazon', 'number', 'sponsor', 'global', 'fedex', 'making', 'ball', 'news', 'community', 'including', 'sent', 'fashion', 'chance', 'christmas', 'respond', 'generation', 'opening', 'project']\n",
            "neighbors of nike: ['white', 'available', 'work', 'home', 'next', 'get', 'puma', 'stock', 'partnership', 'helped', 'grow', 'adidas', 'team', 'lot', 'wait', 'amazon', 'abc', 'business', 'bet', 'ad', 'beautiful', 'time', 'jumpman23', 'look', 'good', 'black', 'apple', 'think', 'people', 'care', 'underarmour', 'working', 'win', 'guy', 'see', 'way', 'keep', 'say', 'top', 'going', 'year', 'moment', 'show', 'understand', \"they're\", 'making', 'tweet', 'want', 'others', 'space', 'low', 'start', 'getting', 'birthday', 'item', 'thanks', 'given', 'something', 'trying', 'seen', 'issue', 'hand', 'go', 'shoe', 'part', 'support', 'turn', 'join', 'problem', 'new', 'coach', 'sponsor', 'use', 'company', 'package', 'delivery', 'put', 'left', 'le', 'minute', 'delivered', 'week', 'know', 'thing', \"i'm\", 'woman', 'day', 'god', 'waiting', 'red', 'let', 'order', 'congrats', 'customer', 'happy', 'partner', 'retail', 'second', 'season', 'yeah', 'bad', 'lol', 'store', 'ask', 'thought', 'real', 'line', 'york', 'game', 'man', 'many', 'pair', 'size', 'last', 'chance', 'said', 'sold', 'wow', 'club', 'shop', 'shirt', 'please', 'girl', 'point', 'night', 'love', 'today', 'job', 'make', 'money', 'virtual', 'take', 'link', 'right', 'great', 'sure', 'incredible', 'global', 'brand', 'need', 'city', 'stop', 'giving', 'buy', 'started', 'sport', 'story', 'check', 'thank', 'got', 'send', 'hoodie', 'favorite', 'color', 'product', 'model', 'rest', 'world', 'shipping', 'found', 'bring', 'back', 'christmas', 'uniform', 'report', 'high', 'price', 'best', 'ball', 'made', 'big', 'able', 'seeing', 'program', 'purchase', 'school', 'luck', 'street', 'athlete', 'name', 'much', 'welcome', 'holiday', \"can't\", 'number', 'gift', 'fam', 'quality', 'stand', 'mean', 'wrong', 'wish', 'type', 'come', 'cause', 'website', 'sell', 'run', 'fan', 'fedex', 'worst', 'help', 'fit', 'called', 'believe', 'collection', 'super', 'bro', 'lost', 'service', 'ship', 'walmart', 'refund', 'awesome', 'logo', 'pack', 'fun', 'true', 'watch', 'looking', 'give', 'dollar', 'buying', 'shit', 'fresh', 'tell', 'netflix', 'present', 'add', 'gonna', 'full', 'community', 'one', 'ordered', 'happen', 'nice', 'damn', 'paid', 'whole', 'appreciate', 'free', 'anyone', 'word', 'amazing', 'hell', 'mine', 'tried', 'marketing', 'month', 'done', 'long', 'im', 'clothes', 'nothing', 'missing', 'speak', 'little', 'fashion', 'sale', 'online', 'photo', 'follow', 'end', 'question', 'gear', 'nfl', 'first', 'place', 'seems', 'fire', 'yes', 'book', 'cool', 'saw', 'old', 'bought', 'talk', 'social', 'pay', 'hard', 'try', 'fix', 'wearing', 'anything', 'sent', 'hate', 'call', 'gotta', 'video', 'feel', 'deal', \"that's\", 'took', 'hit', 'least', \"we're\", 'life', 'share', 'design', 'hey', 'mcdonalds', 'dude', 'wear', 'went', 'yo', 'face', 'person', 'used', 'talking', 'better', 'reason', 'stuff', 'friday', 'set', 'coming', 'apparel', 'kid', 'excited', 'change', 'live', 'everyone', 'tomorrow', 'head', 'wanted', 'china', 'employee', 'told', 'crazy', 'came', 'clean', 'target', 'fucking', 'find', 'style', 'opportunity', 'running', 'state', 'fact', 'saying', 'nba', 'including', 'goal', 'someone', 'worker', 'move', 'final', 'dropped', 'country', 'hope', 'site', 'men', 'agree', 'future', 'different', 'launch', 'sign', 'family', 'taking', 'ok', 'post', 'sorry', 'as', 'phone', 'member', 'thinking', 'guess', 'list', 'using', 'hour', 'supporting', 'drop', 'yesterday', 'fast', 'morning', 'ready', 'idea', 'perfect', 'hear', 'kind', 'return', 'huge', 'dear', 'asking', 'friend', 'official', 'miss', 'stay', 'special', 'dm', 'experience', 'short', 'everything', 'act', \"i've\", 'like', 'continue', 'read', 'credit', 'oh', 'hold', 'card', 'message', 'congratulation', 'twitter', 'email', 'espn', 'wnba', 'open', 'project', 'pick', 'clothing', 'news', 'early', 'side', 'create', 'market', 'wtf', 'received', 'pic', 'tech', 'respect', 'update', 'smh', 'account', 'sound', 'mind', 'matter', 'happened', 'nft', 'supply', 'proud', 'human', 'entire', 'tonight', 'imagine', 'public', 'hero', 'generation']\n",
            "neighbors of lululemon: ['thank', 'great', 'thanks', 'please', 'make', 'brand', 'order', 'new', 'got', 'good', 'love', 'need', 'day', 'store', 'get', 'know', 'best', 'customer', 'service', 'see', 'time', 'pant', 'look', 'discount', 'worker', 'work', 'take', 'team', 'line', 'year', 'want', 'go', 'today', 'hour', 'company', 'first', 'excited', 'fast']\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "##### Nike & Adidas Bridges #####\n",
            "number of nodes: 249\n",
            "number of edges: 2234\n",
            "\n",
            "nodes: ['basketball', 'prize', 'dunk', 'web', 'playing', 'baseball', 'gold', 'lasership', 'remember', 'fbi', 'suck', 'de', 'chicago', 'kick', 'dope', 'pixel', 'wild', 'history', 'green', 'sock', 'jordan', 'dick', 'reebok', 'cocacola', 'draw', 'nov', 'meta', 'james', 'pathetic', 'total', 'slam', 'adidas', 'medium', 'snkr_twitr', 'rtfktstudios', 'finishline', 'culture', 'lazylionsnft', 'holy', 'beiberlove69', 'mid', 'force', 'yeezy', 'adidasoriginals', 'safe', 'instagram', 'yellow', 'campaign', 'access', 'edition', 'actual', 'grey', 'custom', 'commercial', 'passing', 'kanyewest', 'rodgers', 'selling', 'pepsi', 'ht', 'contract', 'üôåüèΩ', 'adidashoops', 'fly', 'nicekicks', 'king', 'court', 'yall', 'jdsports', 'nfts', 'royal', 'eth', 'chose', 'original', 'michael', 'nikesb', 'sephora', 'statefarm', 'light', 'foot', 'solefed', 'slave', 'jadendaly', 'tho', 'image', 'impossible', 'recent', 'release', 'rtfkt', 'relationship', 'kotd', 'latest', 'boredapeyc', 'dark', 'boot', 'taeyong', 'sneakeradmirals', 'topps', 'boardroom', 'deezle148', 'celebrating', 'announced', 'la', 'gatorade', 'giannis_an34', 'icon', 'child', 'rock', 'ups', 'wanna', 'nike', 'turtlepace5', \"women's\", 'baby', 'leading', 'bot', \"let's\", 'classic', 'leader', 'sizeofficial', 'major', 'america', 'boston', 'ig', 'richsignorelli', 'üôèüèæ', 'navy', 'blue', 'several', 'app', 'boycott', 'shot', 'http', 'stealing', 'soccer', 'collaboration', 'kicksonfire', 'boy', 'introducing', 'adidasus', 'innovation', 'sneaker', 'solesavy', 'iamtmcii', 'dream', 'university', 'december', 'solelinks', 'olive', 'newbalance', 'enter', 'travis', 'lied', 'jack', 'course', 'match', 'player', 'htt', 'raffle', 'senator', 'footlocker', 'charger', 'vp', 'content', 'corporation', 'pink', 'ice', 'eneskanter', \"he's\", 'labor', 'ticket', 'xbox', 'collab', 'digital', 'inspired', 'forum', 'ebay', 'steal', 'detail', 'glad', 'sneakerhead', 'candace_parker', 'shut', 'november', 'student', 'manager', 'yoursneakersaredope', 'league', 'blocked', 'college', 'kingjames', 'converse', 'become', 'grail', 'entering', 'aaron', 'lfc', 'listen', 'date', 'trash', '_talkswithtj', 'signed', 'play', 'triple', 'exclusive', 'nikebasketball', 'air', 'potus', 'celebrate', 'lexxdaturtle', 'biggest', 'jersey', 'boost', 'young', 'metaverse', 'box', 'rule', 'atmos_usa', 'american', 'kaya_alexander5', 'snkrfrkrmag', 'football', 'example', 'ya', 'lmao', 'corporate', 'facility', 'orange', 'sick', 'bright', 'anniversary', 'wonder', 'inspire', 'son', 'fuck', 'nikeservice', 'üôèüèº', 'owner', 'alert', 'snkrs', 'chinese', 'cop', 'nikestore', 'woke', 'retro', 'profit', 'em', 'roblox', 'beyonce']\n",
            "\n",
            "neighbors of adidas: ['nike', 'adidasus', 'adidasoriginals', 'young', 'jersey', 'history', 'play', 'forum', 'mid', 'bot', 'blue', 'light', 'sneaker', 'grey', \"he's\", 'snkr_twitr', 'adidashoops', 'glad', 'em', 'collab', 'icon', 'instagram', 'http', 'woke', 'boy', 'fly', 'court', 'retro', 'total', 'shot', 'original', 'example', 'kanyewest', 'boost', 'passing', 'commercial', 'wanna', 'wild', 'prize', 'college', 'several', 'sock', \"women's\", 'lasership', 'actual', 'cocacola', 'newbalance', 'converse', 'boston', 'dope', \"let's\", 'green', 'player', 'app', 'gold', 'collaboration', 'campaign', 'ice', 'rule', 'sneakerhead', 'release', 'football', 'nfts', 'kick', 'corporation', 'ups', 'sick', 'suck', 'announced', 'classic', 'box', 'inspire', 'reebok', 'gatorade', 'kotd', 'yoursneakersaredope', 'safe', 'celebrate', 'impossible', 'remember', 'match', 'orange', 'exclusive', 'basketball', 'soccer', 'course', 'nikebasketball', 'enter', 'corporate', 'yeezy', 'steal', 'nikestore', 'owner', 'date', 'detail', 'ig', 'medium', 'blocked', 'edition', 'selling', 'foot', 'üôåüèΩ', 'lmao', 'content', 'dream', 'pink', 'rock', 'november', 'footlocker', 'son', 'xbox', 'tho', 'alert', 'pepsi', 'recent', 'trash', 'become', 'innovation', 'boot', 'üôèüèº', 'sneakeradmirals', 'chose', '_talkswithtj', 'james', 'vp', 'fuck', 'anniversary', 'ebay', 'celebrating', 'cop', 'inspired', 'aaron', 'la', 'king', 'ticket', 'signed', 'nicekicks', 'iamtmcii', 'beiberlove69', 'air', 'culture', 'baby', 'yall', 'jack', 'candace_parker', 'holy', 'america', 'jordan', 'force', 'american', 'michael', 'latest', 'sizeofficial', 'slave', 'labor', 'wonder', 'navy', 'royal', 'draw', 'child', 'playing', 'beyonce', 'entering', 'introducing', 'contract', 'baseball', 'dick', 'nov', 'solelinks', 'league', 'stealing', 'major', 'statefarm', 'student', 'snkrs', 'image', 'digital', 'dark', 'dunk', 'chicago', 'triple', 'relationship', 'ya', 'pathetic', 'leader', 'raffle', 'access', 'university', 'charger', 'shut', 'atmos_usa', 'leading', 'chinese', 'kicksonfire', 'üôèüèæ', 'solefed', 'kingjames', 'biggest', 'custom', 'taeyong', 'travis', 'roblox', 'bright', 'turtlepace5', 'grail', 'boycott', 'lexxdaturtle', 'deezle148', 'finishline', 'ht', 'slam', 'jdsports', 'manager', 'htt', 'eneskanter', 'nikesb', 'nikeservice', 'giannis_an34', 'solesavy', 'sephora', 'lfc', 'topps', 'profit', 'listen', 'boredapeyc', 'pixel', 'december', 'fbi', 'rodgers', 'yellow', 'meta', 'richsignorelli', 'lied', 'web', 'metaverse', 'eth', 'rtfktstudios', 'kaya_alexander5', 'facility', 'jadendaly', 'senator', 'potus', 'olive', 'lazylionsnft', 'de', 'boardroom', 'snkrfrkrmag', 'rtfkt']\n",
            "neighbors of nike: [\"women's\", 'air', 'yellow', 'footlocker', 'lasership', 'stealing', 'alert', 'collab', 'snkrs', 'nikebasketball', 'adidas', 'release', 'jordan', 'sick', 'instagram', 'ebay', 'jack', 'fbi', 'potus', 'vp', 'ht', 'dunk', 'sizeofficial', 'royal', 'finishline', 'sneakeradmirals', 'nicekicks', 'snkr_twitr', 'iamtmcii', 'corporation', 'latest', 'play', 'kingjames', 'edition', 'celebrating', 'facility', 'bright', 'grey', 'cocacola', 'steal', 'manager', 'force', 'pixel', 'wild', 'http', 'ice', 'soccer', 'lfc', 'match', 'sock', 'custom', 'jersey', 'remember', 'app', 'blue', 'htt', 'several', 'actual', 'snkrfrkrmag', 'atmos_usa', 'üôèüèº', 'nikestore', 'gatorade', 'dick', 'detail', 'light', 'pink', 'medium', 'olive', 'travis', 'kick', 'total', 'classic', 'green', 'college', 'box', 'sneaker', 'boy', 'orange', 'corporate', 'become', 'pepsi', 'üôåüèΩ', 'chinese', 'shut', 'woke', 'pathetic', 'university', 'image', 'rule', 'kaya_alexander5', 'converse', 'slave', 'labor', 'suck', 'innovation', 'beiberlove69', 'em', 'wonder', 'selling', 'triple', 'foot', 'profit', 'cop', 'content', 'dope', 'ups', 'fuck', 'american', 'campaign', 'draw', 'lexxdaturtle', 'charger', 'ig', 'baby', 'raffle', 'player', 'retro', 'child', 'icon', 'nikeservice', 'navy', 'nikesb', 'glad', 'gold', 'playing', 'yall', 'newbalance', 'trash', 'solefed', 'kicksonfire', 'son', 'anniversary', 'yoursneakersaredope', 'kotd', 'shot', 'dream', 'jadendaly', 'boycott', 'commercial', 'football', 'listen', 'michael', 'sneakerhead', 'young', 'üôèüèæ', 'original', 'exclusive', 'course', 'basketball', 'bot', 'chicago', 'xbox', 'tho', 'adidasus', 'december', 'example', 'dark', 'wanna', 'introducing', 'access', 'date', '_talkswithtj', 'major', 'holy', 'inspire', 'reebok', 'james', 'boston', 'student', 'safe', 'biggest', 'nfts', \"he's\", 'prize', 'la', 'inspired', \"let's\", 'court', 'contract', 'leading', 'league', 'ya', 'boot', 'america', 'jdsports', 'culture', 'mid', 'announced', 'owner', 'grail', 'solelinks', 'collaboration', 'adidasoriginals', 'baseball', 'turtlepace5', 'celebrate', 'november', 'blocked', 'recent', 'lmao', 'signed', 'rock', 'boardroom', 'fly', 'history', 'enter', 'deezle148', 'digital', 'relationship', 'de', 'web', 'king', 'kanyewest', 'boost', 'passing', 'senator', 'entering', 'impossible', 'leader', 'candace_parker', 'solesavy', 'giannis_an34', 'ticket', 'metaverse', 'roblox', 'yeezy', 'adidashoops', 'slam', 'aaron', 'lied', 'nov', 'lazylionsnft', 'chose', 'sephora', 'eneskanter', 'taeyong', 'rtfktstudios', 'forum', 'boredapeyc', 'topps', 'meta', 'eth', 'statefarm', 'rodgers', 'richsignorelli', 'beyonce', 'rtfkt']\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "##### Nike & Lululemon Bridges #####\n",
            "number of nodes: 7\n",
            "number of edges: 12\n",
            "\n",
            "nodes: ['lululemon', 'nike', 'olympics', 'plane', 'bill', 'calling', 'canada']\n",
            "\n",
            "neighbors of nike: ['bill', 'canada', 'calling', 'olympics', 'lululemon', 'plane']\n",
            "neighbors of lululemon: ['bill', 'calling', 'nike', 'canada', 'plane', 'olympics']\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "##### Adidas & Lululemon Bridges #####\n",
            "number of nodes: 2\n",
            "number of edges: 0\n",
            "\n",
            "nodes: ['adidas', 'lululemon']\n",
            "\n",
            "neighbors of adidas: []\n",
            "neighbors of lululemon: []\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Saving and Plotting the Graphs**"
      ],
      "metadata": {
        "id": "73jGMFlwfR8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and plotting the full graph\n",
        "plot_graph(G = Semantic_Graph_cleaned, file_path='semantic_network', use_edge_weight = False, plot_size='large')"
      ],
      "metadata": {
        "id": "N1RUP1lVgGrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d91f39a-9a8c-48bd-d01a-3e5edd38f9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 128591 (\\N{PERSON WITH FOLDED HANDS}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n",
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 127996 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-3}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n",
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 128588 (\\N{PERSON RAISING BOTH HANDS IN CELEBRATION}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n",
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 127997 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-4}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n",
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 127998 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-5}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and plotting the subgraphs\n",
        "plot_graph(G = Semantic_Graph_bridge_all, file_path='semantic_network_bridge_all', use_edge_weight = False, plot_size='small')\n",
        "plot_graph(G = Semantic_Graph_bridge_na, file_path='semantic_network_bridge_nike_adidas', use_edge_weight = False, plot_size='small')\n",
        "plot_graph(G = Semantic_Graph_bridge_nl, file_path='semantic_network_bridge_nike_lululemon', use_edge_weight = False, plot_size='small')\n",
        "plot_graph(G = Semantic_Graph_bridge_al, file_path='semantic_network_bridge_adidas_lululemon', use_edge_weight = False, plot_size='small')"
      ],
      "metadata": {
        "id": "Gh9DWFErgqPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8ee9bc-a5ed-4016-d484-d28220fd7976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 128588 (\\N{PERSON RAISING BOTH HANDS IN CELEBRATION}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n",
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 127997 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-4}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n",
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 128591 (\\N{PERSON WITH FOLDED HANDS}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n",
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 127998 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-5}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n",
            "<ipython-input-8-f9cf177cdd08>:64: UserWarning: Glyph 127996 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-3}) missing from current font.\n",
            "  plt.savefig(print_file_path, format='PNG')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Conclusion/Analysis**"
      ],
      "metadata": {
        "id": "yXoZDQzRzfUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Twitter Mentions Network**"
      ],
      "metadata": {
        "id": "7FTZsrpQzh0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of the 175,077 tweets in the dataset, there were 131,663 unique users. This implies that many of the users engaged at least once with one or more of the major brands. To filter down this large number of users, only users with 2 or more tweets and at least 100,000 followers were selected. This resulted in a group of only 198 users. This concentrated group of users represents the individuals who are most active and who have the largest following on Twitter. Overall, the reduction of users resulted in a user group of 0.15% of the initial population."
      ],
      "metadata": {
        "id": "7qgowUFHztQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By pulling the userid's of the three major brands, we can gain quick insight into which brands have the most mention activity. Nike had the vast majority of interactions, with 120,125 mentions. Following this, Adidas had 36,654 and Lululemon had only 6,294. From this, one could definitely postulate that Nike appears to be the most popular brand amongst the Twitter users. Alternatively, Nike could be the most active/engaging on this particular social media platform."
      ],
      "metadata": {
        "id": "O2zmOWx41U5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Mentions Network: Bridge - All**\n",
        "![Mentions_network_bridge_all](https://drive.google.com/uc?export=view&id=1-DN87bzdYKY1RM23L-JHEmjKjzk0614Y)\n",
        "\n",
        "In the network graph above, we can see the users who interact with each of the three brands. Due to the fact that these users mention all three brands, they can be labeled as bridgers (or bridge users). These users are @deezefi, @wwd, and @uniwatch.\n",
        "\n",
        "The first user, @deezefi, goes by the name DeeZe. This user has multiple Twitter accounts, with the main account having over 250k followers. DeeZe appears to be a social media influencer, who is involved in art, podcasting, and NFTs. It is not immediately obvious as to why this user would be interacting with all three brands.\n",
        "\n",
        "The next user, @wwd (Women's Wear Daily), is a media and news company with over 2.7 million followers on Twitter. This company appears to involve fashion, and thus it is fairly obvious that they would interact with all three apparel brands.\n",
        "\n",
        "The last user, @uniwatch (Uni Watch), is another type of media company that has over 140k followers. Upon brief inspection, this company is a media group that discusses and documents sports fashion, i.e. uniforms and logos. As all three brands sell athletic apparel, it is clear as to why this particular user would be interacting with all brands.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5M30QymX5LWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Mentions Network: Bridge - Nike & Adidas**\n",
        "![Mentions_network_bridge_nike_adidas](https://drive.google.com/uc?export=view&id=1-CmXN22ay7O_V1z2lBW_E5OroISGW08L)\n",
        "\n",
        "The network graph above shows the connections between Nike and Adidas. While both brands are clearly the recipients of a lot of engagement, it appears as though Nike has more frequent mentions. This is represented by the thickness of the edges (lines) in the graph. We can also confirm this with prior knowledge, as an earlier portion of this project showed that Nike has the vast majority of mentions (120,125) compared to Adidas (36,654).\n",
        "\n",
        "Many of the connections between Nike and Adidas appear to be companies or organizations, such as @burgerking, @wnba, and @reebok. It is likely that these entities have some sort of partnership or sponsorship with the two brands. For example, it is likely that the WNBA has teams that are sponsored by either Nike or Adidas."
      ],
      "metadata": {
        "id": "SbZ56cFX6rH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Mentions Network: Bridge - Nike & Lululemon**\n",
        "![Mentions_network_bridge_nike_lululemon](https://drive.google.com/uc?export=view&id=1-FilCWInXxh7NxVdmTdZs2egh0kkZ3xt)\n",
        "\n",
        "The network graph above shows the bridges between Nike and Lululemon. At a glance, this graph has far fewer nodes and connections compared to the previous graph (Nike & Adidas). This may be explained by the fact that Lululemon had the fewest total mentions (6,294).\n",
        "\n",
        "Similar to before, many of the connecting users are companies/organizations, such as @brooksrunning and @khou (a Houston news station). Other connections appear to be individual users, such as @evankirstel and @realrclark25. The latter user, Ryan Clark, is a former NFL player and current sports analyst. Thus, it makes sense that his tweets would involve athletic apparel brands such as Nike and Lululemon. The former user, Evan Kirstel, is a tech influencer and content creator. As with @deezefi (a bridge user identified earlier), it is not immediately clear as to why this user is interacting with these brands.  "
      ],
      "metadata": {
        "id": "8eqIQ6gL8CMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Mentions Network: Bridge - Adidas & Lululemon**\n",
        "![Mentions_network_bridge_adidas_lululemon](https://drive.google.com/uc?export=view&id=1-E9v5N7E-exQOjIgRGMFW754o1rBe-yq)\n",
        "\n",
        "The last mentions network graph shows the connections between Adidas and Lululemon. This graph has only three connecting users, which may be explained by the fact that Adidas and Lululemon had the fewest total mentions.\n",
        "\n",
        "The three connecting users appear to be companies/organizations. The first, @iamwellandgood, is a media and news company focused on wellness. The second, @adweek, is another media and news company. And the third, @predsnhl, is a professional hockey team.\n",
        "\n"
      ],
      "metadata": {
        "id": "NBVsV9YT7luN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Semantic Network**"
      ],
      "metadata": {
        "id": "FtmlxKnEzom6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of the 175,077 tweets in the dataset, there were 78,327 unique words. The top 10 most frequently used words were:\n",
        "- 'nike'\n",
        "- 'adidas'\n",
        "- 'sneakerscouts'\n",
        "- 'eneskanter'\n",
        "- 'xbox'\n",
        "- 'available'\n",
        "- 'day'\n",
        "- 'air'\n",
        "- 'china'\n",
        "- 'kingjames'\n",
        "\n",
        "For the sake of reducing the large number of unique words, only the words that appeared more than 250 times were included. This resulted in 911 unique words, which makes up only ~1.16% of the original number of unique words."
      ],
      "metadata": {
        "id": "ECJ01BePIah-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The full, initial graph contained 911 nodes (reflecting the number of unique words) and 208,165 edges. To reduce the impact on this notebook's RAM, a function was used to only include edges of a minimum weight. As a result, the cleaned semantic network graph contained only 40,032 edges."
      ],
      "metadata": {
        "id": "bbYbSL0Id2aF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Semantic Network: Bridge - Nike & Adidas**\n",
        "![Semantic_network_bridge_nike_adidas](https://drive.google.com/uc?export=view&id=1-5NhqBx7ynHqdvIPvTvK3TuGw1kMFMqe)\n",
        "\n",
        "The network graph above shows the words most commonly used in tweets involving both Nike and Adidas. I have selected to show this particular graph, as it is relatively easier to interpret when compared to the full semantic network graph.\n",
        "\n",
        "Here, we can see several interesting combinations of words. For example, the Nike node is most closely surrounded by multiple color words, such as 'blue', 'grey', 'orange', 'gold', and 'pink'. This suggests that many Twitter users are discussing the color of Nike products. These products are most likely shoes, as words like 'sneaker', 'snkrs', 'nicekicks', and 'sneakeradmirals' are also very close to the Nike node.\n",
        "\n",
        "Another intriguing pairing of words close to the Nike node is 'slave' and 'labor'. This suggests that many Twitter users are discussing the controversial employment practices and labor conditions that Nike has been exposed for.\n",
        "\n",
        "For the Adidas node, the closest words are 'mid', 'dope', 'retro', 'icon', 'access', 'exclusive', and 'instagram'. There is somewhat of a pattern here, as these words appear to reference the quality of Adidas products, i.e. with 'mid', 'dope', and 'retro'. Moreover, the combination of 'access' and 'exclusive' hints at the potential exclusivity of Adidas products.\n"
      ],
      "metadata": {
        "id": "VFrxphDbXfVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Semantic Network: Bridge - Nike & Lululemon**\n",
        "![Semantic_network_bridge_nike_lululemon](https://drive.google.com/uc?export=view&id=1-6CdSpiixMqgegnlXyrwludPcgJe062-)\n",
        "\n",
        "The network graph above shows the word commonalities between Nike and Lululemon. Immediately, we can see that there is a significant difference between this network and the previous one. In fact, this network shows only 5 common words used in tweets regarding both Nike and Lululemon.\n",
        "\n",
        "However, this network is not entirely useless. The words 'canada' and 'olympics' suggest that Canada's Olympic team may be sponsored by these two brands. In fact, a quick Google search shows that Lululemon is sponsoring the team through 2028.\n"
      ],
      "metadata": {
        "id": "LgF2UfkJX282"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **References**"
      ],
      "metadata": {
        "id": "hmxC2EKOwo5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://networkx.org/ (NetworkX)\n",
        "- https://developer.x.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets (Twitter: Standard search API)\n",
        "- https://github.com/Chiuchiyin/marketing-network-analysis/blob/main/marketing_network_analysis_with_twitter_data.ipynb (Reference to a code chunk by Chiuchiyin)"
      ],
      "metadata": {
        "id": "qiy1DyXgwqy6"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}